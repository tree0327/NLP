{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ¤ ë¬¸ì„œ ìœ ì‚¬ë„ (Document Similarity): ë‚´ ì˜í˜¼ì˜ ë‹¨ì§ ì°¾ê¸°\n",
                "\n",
                "ì´ì „ ì‹œê°„ì— ë°°ìš´ **ì½”ì‚¬ì¸ ìœ ì‚¬ë„**ë¥¼ ì‹¤ì „ ë°ì´í„°ì— ì ìš©í•´ì„œ, **\"ì¶”ì²œ ì‹œìŠ¤í…œ\"**ì„ ë§Œë“¤ì–´ë³¼ ê±°ì•¼.\n",
                "\n",
                "> **ë¯¸ì…˜**: ì–´ë–¤ í˜¸í…” ë¦¬ë·°ë¥¼ í•˜ë‚˜ ê³¨ëì„ ë•Œ, ê·¸ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ë‚´ìš©ì„ ë‹´ì€ ë¦¬ë·°ë“¤ì„ ì°¾ì•„ë¼!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë°ì´í„° ì¤€ë¹„ (ë³µìŠµ!)\n",
                "02ë²ˆ íŒŒì¼ì—ì„œ í–ˆë˜ ê²ƒì²˜ëŸ¼ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë²¡í„°í™”í•  ê±°ì•¼. \n",
                "(ì„¤ëª…ì€ 02ë²ˆì„ ì°¸ê³ í•´ì¤˜! ì—¬ê¸°ì„  ë¹ ë¥´ê²Œ ì§€ë‚˜ê°ˆê²Œ ìŠ=3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import glob, os\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from nltk.stem import WordNetLemmatizer\n",
                "import nltk\n",
                "import string\n",
                "\n",
                "# 1. ë°ì´í„° ë¡œë“œ\n",
                "path = './data/OpinosisDataset1.0/topics'\n",
                "all_files = glob.glob(os.path.join(path, '*.data'))\n",
                "\n",
                "filename_list = []\n",
                "opinion_text = []\n",
                "\n",
                "for file in all_files:\n",
                "    df = pd.read_table(file, index_col=None, header=None, encoding='latin1')\n",
                "    filename_ = file.split('/')[-1]\n",
                "    filename = filename_.split('.')[0]\n",
                "    filename_list.append(filename)\n",
                "    opinion_text.append(df.to_string(header=False, index=False))\n",
                "\n",
                "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
                "\n",
                "# 2. ì „ì²˜ë¦¬ í•¨ìˆ˜ (ì–´ê·¼ ì¶”ì¶œ)\n",
                "def LemNormalize(text):\n",
                "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
                "    text = text.lower().translate(remove_punct_dict)\n",
                "    tokens = nltk.word_tokenize(text)\n",
                "    lemmar = WordNetLemmatizer()\n",
                "    return [lemmar.lemmatize(token, pos='v') for token in tokens]\n",
                "\n",
                "# 3. TF-IDF ë²¡í„°í™”\n",
                "tfidf_vect = TfidfVectorizer(\n",
                "    tokenizer=LemNormalize\n",
                "    stop_words='english',\n",
                "    ngram_range=(1,2),\n",
                "    min_df=0.05,\n",
                "    max_df=0.85\n",
                ")\n",
                "\n",
                "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
                "print(\"ì¤€ë¹„ ì™„ë£Œ! í–‰ë ¬ í¬ê¸°:\", feature_vect.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ìœ ì‚¬ë„ ê³„ì‚°: ëª¨ë“  ë¬¸ì„œë¼ë¦¬ ë¹„êµí•˜ê¸° âš”ï¸\n",
                "\n",
                "51ê°œì˜ ë¬¸ì„œê°€ ì„œë¡œ ì–¼ë§ˆë‚˜ ë‹®ì•˜ëŠ”ì§€ ê³„ì‚°í•´ë³¼ê²Œ."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics.pairwise import cosine_similarity\n",
                "\n",
                "# ëª¨ë“  ë¬¸ì„œ(feature_vect)ì™€ ëª¨ë“  ë¬¸ì„œ(feature_vect)ë¥¼ ë¹„êµ!\n",
                "# ê²°ê³¼ëŠ” 51x51 í¬ê¸°ì˜ í‘œ(í–‰ë ¬)ê°€ ë  ê±°ì•¼.\n",
                "pair_similarity = cosine_similarity(feature_vect, feature_vect)\n",
                "\n",
                "print(pair_similarity.shape)\n",
                "print(pair_similarity)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ì¶”ì²œ ì‹œìŠ¤í…œ êµ¬í˜„: ì´ ë¦¬ë·°ì™€ ë¹„ìŠ·í•œ ê±´? ğŸ•µï¸â€â™€ï¸\n",
                "\n",
                "ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ì¶”ì²œì„ í•´ë³´ì. \n",
                "ì˜ˆë¥¼ ë“¤ì–´, **\"bathroom_bestwestern_hotel_sfo\"** (ìƒŒí”„ë€ì‹œìŠ¤ì½” ë² ìŠ¤íŠ¸ì›¨ìŠ¤í„´ í˜¸í…” í™”ì¥ì‹¤) ë¦¬ë·°ë¥¼ ë³´ê³  ìˆëŠ” ì‚¬ëŒì—ê²Œ,\n",
                "ë‹¤ë¥¸ ë¹„ìŠ·í•œ í˜¸í…” ë¦¬ë·°ë¥¼ ì¶”ì²œí•´ì£¼ê³  ì‹¶ì–´."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. ìš°ë¦¬ê°€ ê¸°ì¤€ìœ¼ë¡œ ì‚¼ì„ ë¦¬ë·° ì°¾ê¸°\n",
                "# íŒŒì¼ëª…ì— 'bathroom_bestwestern'ì´ ë“¤ì–´ê°€ëŠ” ë¬¸ì„œ ì°¾ê¸°\n",
                "target_idx = document_df[document_df['filename'].str.contains('bathroom_bestwestern')].index[0]\n",
                "\n",
                "print(f\"ê¸°ì¤€ ë¬¸ì„œ ì¸ë±ìŠ¤: {target_idx}\")\n",
                "print(f\"íŒŒì¼ëª…: {document_df.iloc[target_idx]['filename']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "\n",
                "# 2. ì´ ë¬¸ì„œ(target_idx)ì™€ ë‹¤ë¥¸ ëª¨ë“  ë¬¸ì„œ ê°„ì˜ ìœ ì‚¬ë„ ê°€ì ¸ì˜¤ê¸°\n",
                "my_similarity = pair_similarity[target_idx]\n",
                "\n",
                "# 3. ìœ ì‚¬ë„ê°€ ë†’ì€ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (argsort í™œìš©)\n",
                "# argsort()ëŠ” ê°’ì„ ì •ë ¬í•˜ëŠ” ê²Œ ì•„ë‹ˆë¼, 'ì •ë ¬ëœ ì¸ë±ìŠ¤'ë¥¼ ë°˜í™˜í•´.\n",
                "# ê·¼ë° ê¸°ë³¸ì´ ì˜¤ë¦„ì°¨ìˆœ(ì‘ì€ê±° -> í°ê±°)ì´ë¼ì„œ, [::-1]ë¡œ ë’¤ì§‘ì–´ì„œ ë‚´ë¦¼ì°¨ìˆœ(í°ê±° -> ì‘ì€ê±°)ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼ í•´.\n",
                "sorted_idx = my_similarity.argsort()[::-1]\n",
                "\n",
                "# 4. ìê¸° ìì‹ (1ë“±)ì€ ì œì™¸í•˜ê³ , 2ë“±ë¶€í„° 6ë“±ê¹Œì§€ë§Œ ë½‘ì•„ë³´ì (Top 5)\n",
                "top_5_idx = sorted_idx[1:6]\n",
                "\n",
                "print(\"ê°€ì¥ ë¹„ìŠ·í•œ ë¦¬ë·° Top 5:\")\n",
                "print(document_df.iloc[top_5_idx]['filename'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ” ê²°ê³¼ ë¶„ì„\n",
                "ê²°ê³¼ë¥¼ ë³´ë©´ **\"room_holiday_inn\"**, **\"rooms_swissotel\"** ì²˜ëŸ¼ \n",
                "ë‹¤ë¥¸ í˜¸í…”ì˜ **ë°©/í™”ì¥ì‹¤** ê´€ë ¨ ë¦¬ë·°ë“¤ì´ ì¶”ì²œëœ ê±¸ ë³¼ ìˆ˜ ìˆì–´.\n",
                "\n",
                "ì¦‰, ì»´í“¨í„°ê°€ ë‚´ìš©ë§Œ ë³´ê³ ë„ **\"ì•„, ì´ ì‚¬ëŒì€ í˜¸í…” ì‹œì„¤ì— ê´€ì‹¬ì´ ìˆêµ¬ë‚˜!\"** ë¼ê³  íŒŒì•…í•œ ê±°ì§€. ëŒ€ë‹¨í•˜ì§€? ğŸ‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q. `cosine_similarity(A, B)`ì˜ ê²°ê³¼ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë‘ ë¬¸ì„œëŠ”?**\n",
                "1. ë§¤ìš° ë¹„ìŠ·í•˜ë‹¤.\n",
                "2. ì „í˜€ ê´€ê³„ ì—†ë‹¤.\n",
                "3. ë°˜ëŒ€ ë‚´ìš©ì´ë‹¤.\n",
                "\n",
                "<details>\n",
                "<summary>ì •ë‹µ í™•ì¸</summary>\n",
                "\n",
                "**1ë²ˆ ë§¤ìš° ë¹„ìŠ·í•˜ë‹¤**\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
