{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ“‚ ë¬¸ì„œ êµ°ì§‘í™” (Document Clustering): ë’¤ì£½ë°•ì£½ ë¬¸ì„œ ì •ë¦¬í•˜ê¸°\n",
                "\n",
                "ì•ˆë…•! ì´ë²ˆì—ëŠ” **'ë‹µì´ ì—†ëŠ” ë¬¸ì œ'**ë¥¼ í’€ì–´ë³¼ ê±°ì•¼. \n",
                "ì´ì „ê¹Œì§€ëŠ” \"ì´ê±´ ì‚¬ê³¼ì•¼, ì´ê±´ ë°°ì•¼\"ë¼ê³  ì•Œë ¤ì£¼ëŠ”(ì§€ë„ í•™ìŠµ) ë°©ì‹ì´ì—ˆë‹¤ë©´, \n",
                "ì´ë²ˆì—ëŠ” **\"ê·¸ëƒ¥ ì´ê±° ë‹¤ ì„ì—¬ ìˆëŠ”ë°, ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ë¬¶ì–´ë´!\"** ë¼ê³  ì‹œí‚¤ëŠ” **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)**, ê·¸ ì¤‘ì—ì„œë„ **êµ°ì§‘í™”(Clustering)**ë¥¼ ë°°ìš¸ ê±°ì•¼.\n",
                "\n",
                "> **ë¹„ìœ **: ë¹¨ë˜ ë°”êµ¬ë‹ˆì— ì–‘ë§, í‹°ì…”ì¸ , ë°”ì§€ê°€ ë§ˆêµ¬ ì„ì—¬ ìˆì–´. ì´ê±¸ 'ì–‘ë§ ë”ë¯¸', 'í‹°ì…”ì¸  ë”ë¯¸', 'ë°”ì§€ ë”ë¯¸'ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì´ë¼ê³  ìƒê°í•˜ë©´ ë¼!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°: í©ì–´ì§€ íŒŒì¼ ëª¨ìœ¼ê¸° ğŸ—‚ï¸\n",
                "\n",
                "ì´ë²ˆì— ì“¸ ë°ì´í„°ëŠ” í˜¸í…”, ìë™ì°¨, ì „ìê¸°ê¸° ë“±ì— ëŒ€í•œ **ë¦¬ë·° ë°ì´í„°**ì•¼. \n",
                "ê·¸ëŸ°ë° íŒŒì¼ì´ í•˜ë‚˜ë¡œ ì˜ˆì˜ê²Œ ì •ë¦¬ëœ ê²Œ ì•„ë‹ˆë¼, ì£¼ì œë³„ë¡œ 51ê°œì˜ íŒŒì¼ì´ í©ì–´ì ¸ ìˆì–´. ì´ê±¸ í•˜ë‚˜ë¡œ ëª¨ìœ¼ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ì.\n",
                "\n",
                "### ğŸ› ï¸ íŒŒì¼ ë‹¤ë£¨ëŠ” ë„êµ¬ë“¤\n",
                "- `os`: ìœˆë„ìš°/ë§¥ ê°™ì€ ìš´ì˜ì²´ì œ ê¸°ëŠ¥ì„ ë¹Œë ¤ ì“°ëŠ” ë„êµ¬ (í´ë” ê²½ë¡œ ì°¾ê¸° ë“±)\n",
                "- `glob`: \"*.txt\" ì²˜ëŸ¼ íŠ¹ì • íŒ¨í„´ì„ ê°€ì§„ íŒŒì¼ë“¤ì„ ëª½ë•… ì°¾ì•„ì£¼ëŠ” ë„êµ¬"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ë°œê²¬ëœ íŒŒì¼ ê°œìˆ˜: 51ê°œ\n",
                        "ì²« 3ê°œ íŒŒì¼ë§Œ ë³¼ê¹Œ? ['./data/OpinosisDataset1.0/topics/battery-life_ipod_nano_8gb.txt.data', './data/OpinosisDataset1.0/topics/gas_mileage_toyota_camry_2007.txt.data', './data/OpinosisDataset1.0/topics/room_holiday_inn_london.txt.data']\n"
                    ]
                }
            ],
            "source": [
                "import pandas as pd\n",
                "import glob, os\n",
                "\n",
                "# 1. ë°ì´í„°ê°€ ìˆëŠ” í´ë” ê²½ë¡œ ì„¤ì • (ë„¤ ì»´í“¨í„° í™˜ê²½ì— ë§ê²Œ ê²½ë¡œê°€ ì˜ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸!)\n",
                "path = './data/OpinosisDataset1.0/topics'\n",
                "\n",
                "# 2. í•´ë‹¹ í´ë” ì•ˆì— ìˆëŠ” ëª¨ë“  .data íŒŒì¼(*.data)ì˜ ì´ë¦„ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
                "all_files = glob.glob(os.path.join(path, '*.data'))\n",
                "\n",
                "print(f\"ë°œê²¬ëœ íŒŒì¼ ê°œìˆ˜: {len(all_files)}ê°œ\")\n",
                "print(\"ì²« 3ê°œ íŒŒì¼ë§Œ ë³¼ê¹Œ?\", all_files[:3])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ“ íŒŒì¼ ì½ì–´ì„œ í‘œ(DataFrame)ë¡œ ë§Œë“¤ê¸°\n",
                "ì´ì œ ì°¾ì•„ë‚¸ íŒŒì¼ë“¤ì„ í•˜ë‚˜ì”© ì½ì–´ì„œ, **(íŒŒì¼ëª…, ë¦¬ë·°ë‚´ìš©)** í˜•íƒœì˜ í‘œë¡œ ì •ë¦¬í•  ê±°ì•¼."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>filename</th>\n",
                            "      <th>opinion_text</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>battery-life_ipod_nano_8gb</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>gas_mileage_toyota_camry_2007</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>room_holiday_inn_london</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>location_holiday_inn_london</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>staff_bestwestern_hotel_sfo</td>\n",
                            "      <td>...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                        filename  \\\n",
                            "0     battery-life_ipod_nano_8gb   \n",
                            "1  gas_mileage_toyota_camry_2007   \n",
                            "2        room_holiday_inn_london   \n",
                            "3    location_holiday_inn_london   \n",
                            "4    staff_bestwestern_hotel_sfo   \n",
                            "\n",
                            "                                        opinion_text  \n",
                            "0                                                ...  \n",
                            "1                                                ...  \n",
                            "2                                                ...  \n",
                            "3                                                ...  \n",
                            "4                                                ...  "
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "filename_list = []  # íŒŒì¼ ì œëª©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
                "opinion_text = []   # íŒŒì¼ ë‚´ìš©ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸\n",
                "\n",
                "for file in all_files:\n",
                "    # 1. íŒŒì¼ ì½ê¸° (Latin-1 ì¸ì½”ë”© ì‚¬ìš©)\n",
                "    df = pd.read_table(file, index_col=None, header=None, encoding='latin1')\n",
                "    \n",
                "    # 2. íŒŒì¼ëª… ì˜ˆì˜ê²Œ ë‹¤ë“¬ê¸° (ê²½ë¡œ ì œê±°, í™•ì¥ì ì œê±°)\n",
                "    # ì˜ˆ: './data/.../battery_life.data' -> 'battery_life'\n",
                "    filename_ = file.split('/')[-1] # ê²½ë¡œ êµ¬ë¶„ì(/)ë¡œ ìë¥´ê³  ë§¨ ë’¤ì—êº¼(íŒŒì¼ëª…)ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
                "    filename = filename_.split('.')[0] # ì (.)ìœ¼ë¡œ ìë¥´ê³  ì•ì—êº¼(í™•ì¥ì ì œì™¸)ë§Œ ê°€ì ¸ì˜¤ê¸°\n",
                "    filename_list.append(filename)\n",
                "\n",
                "    # 3. íŒŒì¼ ë‚´ìš©ì„ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°\n",
                "    opinion_text.append(df.to_string(header=False, index=False))\n",
                "\n",
                "# 4. DataFrameìœ¼ë¡œ ë³€í™˜\n",
                "document_df = pd.DataFrame({'filename':filename_list, 'opinion_text':opinion_text})\n",
                "document_df.head() # ìƒìœ„ 5ê°œë§Œ í™•ì¸"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ì „ì²˜ë¦¬ ë° ë²¡í„°í™”: ì»´í“¨í„°ê°€ ì½ê¸° í¸í•˜ê²Œ ğŸ§¹\n",
                "\n",
                "ì´ì „ì— ë°°ì› ë˜ **TF-IDF**ë¥¼ ì‚¬ìš©í•  ê±°ì•¼. \n",
                "ì´ë²ˆì—ëŠ” ì¡°ê¸ˆ ë” ê³ ê¸‰ ê¸°ìˆ ì„ ì¶”ê°€í•´ë³´ì.\n",
                "\n",
                "### ğŸ”© ì–´ê·¼ ì¶”ì¶œ (Lemmatization)\n",
                "- `running`, `runs`, `ran` -> ëª¨ë‘ `run`ìœ¼ë¡œ í†µì¼í•˜ëŠ” ì‘ì—…ì´ì•¼.\n",
                "- ë‹¨ì–´ì˜ 'ë¿Œë¦¬'ë¥¼ ì°¾ì•„ì£¼ë©´ ì»´í“¨í„°ê°€ ë” ì •í™•í•˜ê²Œ ì˜ë¯¸ë¥¼ íŒŒì•…í•  ìˆ˜ ìˆì–´."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n",
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n"
                    ]
                }
            ],
            "source": [
                "from nltk.stem import WordNetLemmatizer\n",
                "import nltk\n",
                "import string\n",
                "\n",
                "# NLTK ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ (í•œë²ˆë§Œ í•˜ë©´ ë¨)\n",
                "# nltk.download('punkt')\n",
                "# nltk.download('wordnet')\n",
                "\n",
                "# ë‚˜ë§Œì˜ í† í°í™” í•¨ìˆ˜ ë§Œë“¤ê¸° (íŠ¹ìˆ˜ë¬¸ì ì œê±° + ì–´ê·¼ ì¶”ì¶œ)\n",
                "def LemNormalize(text):\n",
                "    # 1. ì†Œë¬¸ì ë³€í™˜\n",
                "    text = text.lower()\n",
                "    \n",
                "    # 2. íŠ¹ìˆ˜ë¬¸ì ì œê±° (ë”•ì…”ë„ˆë¦¬ í™œìš©)\n",
                "    # ord(): ë¬¸ìë¥¼ ìˆ«ìë¡œ ë³€í™˜. ì˜ˆ: '!' -> 33\n",
                "    # remove_punct_dict = {33: None, ...} ì´ëŸ° ì‹ì´ì•¼. íŠ¹ìˆ˜ë¬¸ìë¥¼ ë§Œë‚˜ë©´ None(ì‚­ì œ)ìœ¼ë¡œ ë°”ê¿”ë¼!\n",
                "    remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
                "    text = text.translate(remove_punct_dict)\n",
                "    \n",
                "    # 3. ë‹¨ì–´ í† í°í™”\n",
                "    tokens = nltk.word_tokenize(text)\n",
                "    \n",
                "    # 4. ì–´ê·¼ ì¶”ì¶œ (ë™ì‚¬ ê¸°ì¤€)\n",
                "    lemmar = WordNetLemmatizer()\n",
                "    return [lemmar.lemmatize(token, pos='v') for token in tokens]"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ”¢ TF-IDF ì„¤ì •í•˜ê¸°\n",
                "- `tokenizer`: ë°©ê¸ˆ ë§Œë“  ì–´ê·¼ ì¶”ì¶œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©.\n",
                "- `stop_words`: ì˜ì–´ ë¶ˆìš©ì–´ ì œê±°.\n",
                "- `ngram_range`: (1, 2) -> ë‹¨ì–´ 1ê°œì§œë¦¬ì™€ 2ê°œì§œë¦¬ ë¬¶ìŒ(Bi-gram)ì„ ëª¨ë‘ ì‚¬ìš©.\n",
                "- `min_df=0.05`, `max_df=0.85`: \n",
                "    - ë„ˆë¬´ í¬ê·€í•œ ë‹¨ì–´(5% ë¯¸ë§Œ ë“±ì¥)ëŠ” ë²„ë¦¬ê³ ,\n",
                "    - ë„ˆë¬´ í”í•œ ë‹¨ì–´(85% ì´ìƒ ë“±ì¥)ë„ ë²„ë ¤ì„œ í•µì‹¬ ë‹¨ì–´ë§Œ ë‚¨ê¸°ê¸°!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:526: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
                        "  warnings.warn(\n",
                        "/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:411: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['make'] not in stop_words.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ë²¡í„°í™” ì™„ë£Œ! í–‰ë ¬ í¬ê¸°: (51, 4072)\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "tfidf_vect = TfidfVectorizer(\n",
                "    tokenizer=LemNormalize, \n",
                "    stop_words='english', \n",
                "    ngram_range=(1,2), \n",
                "    min_df=0.05,\n",
                "    max_df=0.85\n",
                ")\n",
                "\n",
                "# í•™ìŠµ ë° ë³€í™˜ ìˆ˜í–‰\n",
                "feature_vect = tfidf_vect.fit_transform(document_df['opinion_text'])\n",
                "\n",
                "print(\"ë²¡í„°í™” ì™„ë£Œ! í–‰ë ¬ í¬ê¸°:\", feature_vect.shape)\n",
                "# (ë¬¸ì„œ 51ê°œ, ë‹¨ì–´ ì•½ 4000ì—¬ê°œ)ì˜ í–‰ë ¬ì´ ë§Œë“¤ì–´ì¡Œì„ ê±°ì•¼."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. K-Means êµ°ì§‘í™”: ë¼ë¦¬ë¼ë¦¬ ë­‰ì³ë¼! ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦\n",
                "\n",
                "> **\"ëª¨ë¥´ëŠ” ì‚¬ëŒë“¤ 51ëª…ì„ ê°•ë‹¹ì— í’€ì–´ë†“ê³ , ì„±í–¥ì´ ë¹„ìŠ·í•œ 5ê°œ ê·¸ë£¹ìœ¼ë¡œ ì•Œì•„ì„œ ëª¨ì´ë¼ê³  í•˜ëŠ” ê²ƒ\"**\n",
                "\n",
                "**K-Means ì•Œê³ ë¦¬ì¦˜**ì€ ê°€ì¥ ëŒ€í‘œì ì¸ êµ°ì§‘í™” ë°©ë²•ì´ì•¼.\n",
                "1. ì„ì˜ì˜ ì¤‘ì‹¬ì (Centroid) Kê°œë¥¼ ì°ì–´.\n",
                "2. ê° ë°ì´í„°ëŠ” ê°€ì¥ ê°€ê¹Œìš´ ì¤‘ì‹¬ì  íŒ€ìœ¼ë¡œ ë“¤ì–´ê°€.\n",
                "3. íŒ€ì›ë“¤ì˜ í‰ê·  ìœ„ì¹˜ë¡œ ì¤‘ì‹¬ì ì„ ì´ë™ì‹œì¼œ.\n",
                "4. ì¤‘ì‹¬ì ì´ ë” ì´ìƒ ì•ˆ ì›€ì§ì¼ ë•Œê¹Œì§€ 2~3ë²ˆ ë°˜ë³µ!\n",
                "\n",
                "ìš°ë¦¬ëŠ” ì£¼ì œê°€ ëŒ€ì¶© 5ê°œ ì •ë„(í˜¸í…”, ìë™ì°¨, ì „ìê¸°ê¸° ë“±) ë  ê±°ë¼ê³  ì˜ˆìƒí•˜ê³  **K=5**ë¡œ ì„¤ì •í•´ë³¼ê²Œ."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>filename</th>\n",
                            "      <th>opinion_text</th>\n",
                            "      <th>cluster_label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>battery-life_ipod_nano_8gb</td>\n",
                            "      <td>...</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>gas_mileage_toyota_camry_2007</td>\n",
                            "      <td>...</td>\n",
                            "      <td>4</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>room_holiday_inn_london</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>location_holiday_inn_london</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>staff_bestwestern_hotel_sfo</td>\n",
                            "      <td>...</td>\n",
                            "      <td>3</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                        filename  \\\n",
                            "0     battery-life_ipod_nano_8gb   \n",
                            "1  gas_mileage_toyota_camry_2007   \n",
                            "2        room_holiday_inn_london   \n",
                            "3    location_holiday_inn_london   \n",
                            "4    staff_bestwestern_hotel_sfo   \n",
                            "\n",
                            "                                        opinion_text  cluster_label  \n",
                            "0                                                ...              1  \n",
                            "1                                                ...              4  \n",
                            "2                                                ...              3  \n",
                            "3                                                ...              0  \n",
                            "4                                                ...              3  "
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.cluster import KMeans\n",
                "\n",
                "# 1. ëª¨ë¸ ìƒì„± (êµ°ì§‘ 5ê°œ)\n",
                "km_cluster = KMeans(n_clusters=5, max_iter=10000, random_state=0)\n",
                "\n",
                "# 2. í•™ìŠµ ë° ì˜ˆì¸¡\n",
                "# feature_vect(TF-IDF ë°ì´í„°)ë¥¼ ë„£ìœ¼ë©´, ê° ë¬¸ì„œê°€ 0, 1, 2, 3, 4 ì¤‘ ì–´ëŠ ê·¸ë£¹ì¸ì§€ ì•Œë ¤ì¤Œ\n",
                "km_cluster.fit(feature_vect)\n",
                "cluster_label = km_cluster.labels_ # ê° ë¬¸ì„œì˜ ê·¸ë£¹ ë²ˆí˜¸\n",
                "cluster_centers = km_cluster.cluster_centers_ # ê° ê·¸ë£¹ì˜ ì¤‘ì‹¬ì  ì¢Œí‘œ\n",
                "\n",
                "# 3. ê²°ê³¼ ì €ì¥\n",
                "document_df['cluster_label'] = cluster_label\n",
                "document_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ“Š ê²°ê³¼ í™•ì¸: ì˜ ë¬¶ì˜€ì„ê¹Œ?\n",
                "ê° ê·¸ë£¹(Cluster)ë³„ë¡œ ì–´ë–¤ ë¬¸ì„œë“¤ì´ ëª¨ì˜€ëŠ”ì§€ í™•ì¸í•´ë³´ì.\n",
                "íŒŒì¼ ì´ë¦„ì„ ë³´ë©´ ëŒ€ì¶© ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ëª¨ì˜€ëŠ”ì§€ ì•Œ ìˆ˜ ìˆê² ì§€?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "####### Cluster 0 #######\n",
                        "['food_holiday_inn_london', 'food_swissotel_chicago', 'location_holiday_inn_london', 'price_amazon_kindle', 'price_holiday_inn_london', 'service_bestwestern_hotel_sfo', 'service_holiday_inn_london', 'service_swissotel_hotel_chicago']\n",
                        "\n",
                        "####### Cluster 1 #######\n",
                        "['accuracy_garmin_nuvi_255W_gps', 'battery-life_amazon_kindle', 'battery-life_ipod_nano_8gb', 'battery-life_netbook_1005ha', 'buttons_amazon_kindle', 'directions_garmin_nuvi_255W_gps', 'display_garmin_nuvi_255W_gps', 'eyesight-issues_amazon_kindle', 'features_windows7', 'fonts_amazon_kindle', 'keyboard_netbook_1005ha', 'navigation_amazon_kindle', 'performance_netbook_1005ha', 'satellite_garmin_nuvi_255W_gps', 'screen_garmin_nuvi_255W_gps', 'screen_ipod_nano_8gb', 'screen_netbook_1005ha', 'size_asus_netbook_1005ha', 'sound_ipod_nano_8gb', 'speed_garmin_nuvi_255W_gps', 'speed_windows7', 'updates_garmin_nuvi_255W_gps', 'video_ipod_nano_8gb', 'voice_garmin_nuvi_255W_gps']\n",
                        "\n",
                        "####### Cluster 2 #######\n",
                        "['interior_honda_accord_2008', 'interior_toyota_camry_2007', 'quality_toyota_camry_2007']\n",
                        "\n",
                        "####### Cluster 3 #######\n",
                        "['bathroom_bestwestern_hotel_sfo', 'free_bestwestern_hotel_sfo', 'location_bestwestern_hotel_sfo', 'parking_bestwestern_hotel_sfo', 'room_holiday_inn_london', 'rooms_bestwestern_hotel_sfo', 'rooms_swissotel_chicago', 'staff_bestwestern_hotel_sfo', 'staff_swissotel_chicago']\n",
                        "\n",
                        "####### Cluster 4 #######\n",
                        "['comfort_honda_accord_2008', 'comfort_toyota_camry_2007', 'gas_mileage_toyota_camry_2007', 'mileage_honda_accord_2008', 'performance_honda_accord_2008', 'seats_honda_accord_2008', 'transmission_toyota_camry_2007']\n"
                    ]
                }
            ],
            "source": [
                "# ê·¸ë£¹ë³„ë¡œ ì¶œë ¥í•´ì„œ í™•ì¸í•´ë³´ê¸°\n",
                "for i in range(5):\n",
                "    print(f\"\\n####### Cluster {i} #######\")\n",
                "    # í•´ë‹¹ ê·¸ë£¹ì— ì†í•œ ë¬¸ì„œë“¤ì˜ íŒŒì¼ëª…ë§Œ ë½‘ì•„ì„œ ì¶œë ¥\n",
                "    print(document_df[document_df['cluster_label']==i]['filename'].sort_values().tolist())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ•µï¸â€â™‚ï¸ ê²°ê³¼ í•´ì„\n",
                "ì‹¤í–‰ ê²°ê³¼ë¥¼ ë³´ë©´ ë†€ëê²Œë„ ë¹„ìŠ·í•œ ì£¼ì œë¼ë¦¬ ëª¨ì¸ ê±¸ ë³¼ ìˆ˜ ìˆì„ ê±°ì•¼.\n",
                "- ì–´ë–¤ ê·¸ë£¹ì€ **ìë™ì°¨** ê´€ë ¨(Toyota, Honda...)\n",
                "- ì–´ë–¤ ê·¸ë£¹ì€ **í˜¸í…”** ê´€ë ¨(Hotel, Inn, Room...)\n",
                "- ì–´ë–¤ ê·¸ë£¹ì€ **ì „ìê¸°ê¸°** ê´€ë ¨(iPod, Kindle...)\n",
                "\n",
                "ì»´í“¨í„°ëŠ” ë‹¨ì–´ë“¤ì˜ **ë“±ì¥ íŒ¨í„´(í†µê³„)**ë§Œ ë³´ê³  ì´ë ‡ê²Œ ì£¼ì œë¥¼ ë¶„ë¥˜í•´ë‚¸ ê±°ì•¼. ì‹ ê¸°í•˜ì§€? ğŸ˜"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q1. ì •ë‹µì„ ì•Œë ¤ì£¼ì§€ ì•Šê³  ë°ì´í„°ì˜ íŠ¹ì§•ë§Œìœ¼ë¡œ ë¹„ìŠ·í•œ ê²ƒë¼ë¦¬ ë¬¶ëŠ” í•™ìŠµ ë°©ì‹ì„ ë¬´ì—‡ì´ë¼ í• ê¹Œ?**\n",
                "1. ì§€ë„ í•™ìŠµ (Supervised Learning)\n",
                "2. ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)\n",
                "3. ê°•í™” í•™ìŠµ (Reinforcement Learning)\n",
                "\n",
                "**Q2. TF-IDF íŒŒë¼ë¯¸í„° ì¤‘, ë¬¸ì„œì— 'ë„ˆë¬´ ìì£¼(ì˜ˆ: 85% ì´ìƒ)' ë“±ì¥í•˜ëŠ” ë‹¨ì–´ë¥¼ ë°°ì œí•˜ëŠ” ì˜µì…˜ì€?**\n",
                "1. min_df\n",
                "2. max_df\n",
                "3. ngram_range"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**ì •ë‹µ**\n",
                "\n",
                "<details>\n",
                "<summary>í´ë¦­í•´ì„œ í™•ì¸!</summary>\n",
                "\n",
                "1. **2ë²ˆ ë¹„ì§€ë„ í•™ìŠµ** (ì„ ìƒë‹˜ ì—†ì´ ìŠ¤ìŠ¤ë¡œ ê³µë¶€í•˜ê¸°!)\n",
                "2. **2ë²ˆ max_df** (ë„ˆë¬´ í”í•˜ë©´ íŠ¹ì§•ì´ ì•ˆ ë˜ë‹ˆê¹Œ ìœ„ì—ì„œ ì˜ë¼ëƒ„!)\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
