{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ“˜ ìì—°ì–´ ì²˜ë¦¬(NLP) ê¸°ì´ˆ: í…ìŠ¤íŠ¸ ë¶„ì„ A to Z\n",
                "\n",
                "ì•ˆë…•! ì˜¤ëŠ˜ì€ **í…ìŠ¤íŠ¸ ë¶„ì„(Text Analysis)**ì˜ ì„¸ê³„ì— ì˜¨ ê±¸ í™˜ì˜í•´. ğŸ‘‹\n",
                "ìš°ë¦¬ê°€ ë§¤ì¼ ì“°ëŠ” 'ë§'ê³¼ 'ê¸€'ì„ ì»´í“¨í„°ê°€ ì–´ë–»ê²Œ ì´í•´í•˜ê³  ë¶„ì„í•˜ëŠ”ì§€, ì•„ì£¼ ê¸°ì´ˆë¶€í„° ì°¨ê·¼ì°¨ê·¼ ì•Œë ¤ì¤„ê²Œ.\n",
                "\n",
                "ë³µì¡í•´ ë³´ì´ì§€ë§Œ í•µì‹¬ì€ ê°„ë‹¨í•´. **\"ê¸€ìë¥¼ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ì(ë²¡í„°)ë¡œ ë°”ê¾¸ëŠ” ê³¼ì •\"**ì´ì•¼.\n",
                "ë§ˆì¹˜ ìš”ë¦¬ ì¬ë£Œë¥¼ ì†ì§ˆí•´ì„œ ë§›ìˆëŠ” ìš”ë¦¬ë¥¼ ë§Œë“œëŠ” ê²ƒì²˜ëŸ¼, í…ìŠ¤íŠ¸ë¥¼ ë‹¤ë“¬ê³  ë¶„ì„í•˜ëŠ” ë°©ë²•ì„ í•˜ë‚˜ì”© ë°°ì›Œë³´ì!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. í…ìŠ¤íŠ¸ ë¶„ì„ì´ ë­ì•¼?\n",
                "\n",
                "- **ìì—°ì–´ ì²˜ë¦¬ (NLP)**: ì‚¬ëŒì´ ì“°ëŠ” ì–¸ì–´(ìì—°ì–´)ë¥¼ ì»´í“¨í„°ê°€ ì•Œì•„ë“£ê²Œ í•˜ëŠ” ê¸°ìˆ ì´ì•¼. (ë²ˆì—­ê¸°, ì‹œë¦¬/ì§€ë‹ˆ, ì±—ë´‡ ë“±)\n",
                "- **í…ìŠ¤íŠ¸ ë¶„ì„**: í…ìŠ¤íŠ¸ì—ì„œ ì˜ë¯¸ ìˆëŠ” ì •ë³´ë¥¼ ë½‘ì•„ë‚´ëŠ” ê±°ì•¼. (ì´ ê¸€ì´ ê¸ì •ì ì¸ì§€ ë¶€ì •ì ì¸ì§€, ì£¼ì œê°€ ë­”ì§€ ë“±)\n",
                "\n",
                "### ğŸ› ï¸ ì˜¤ëŠ˜ ì‚¬ìš©í•  ë„êµ¬ë“¤ (Python Libraries)\n",
                "ìš°ë¦¬ëŠ” íŒŒì´ì¬ì´ ì œê³µí•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ë“¤ì„ ì‚¬ìš©í•  ê±°ì•¼. ê°ê°ì˜ íŠ¹ì§•ì„ í‘œë¡œ ì •ë¦¬í–ˆì–´.\n",
                "\n",
                "| **íŒ¨í‚¤ì§€** | **ë¹„ìœ ** | **ì£¼ìš” ì—­í• ** |\n",
                "|:---:|:---:|:---|\n",
                "| **NLTK** | ğŸ›ï¸ ê±°ëŒ€í•œ ë„ì„œê´€ | ê°€ì¥ ì˜¤ë˜ë˜ê³  ë°©ëŒ€í•œ NLP ìë£Œì™€ ë„êµ¬ë¥¼ ê°€ì§„ í• ì•„ë²„ì§€ ê°™ì€ ì¡´ì¬. |\n",
                "| **Gensim** | ğŸ•¸ï¸ ê±°ë¯¸ | ë¬¸ì„œë“¤ ì‚¬ì´ì˜ ìœ ì‚¬ë„ë¥¼ ì¸¡ì •í•˜ê±°ë‚˜ ì£¼ì œë¥¼ ì°¾ëŠ”ë° íŠ¹í™”ë˜ì–´ ìˆì–´. |\n",
                "| **Spacy** | ğŸï¸ ìŠ¤í¬ì¸ ì¹´ | ë¹ ë¥´ê³  ìµœì‹  ê¸°ìˆ ì´ ì ìš©ë˜ì–´ì„œ ì‹¤ë¬´ì—ì„œ ì•„ì£¼ ë§ì´ ì¨. |\n",
                "| **KoNLPy** | ğŸ‡°ğŸ‡· ì„¸ì¢…ëŒ€ì™• | í•œêµ­ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œëŠ” ì´ ì¹œêµ¬ê°€ í•„ìˆ˜ì•¼! (í•œê¸€ í˜•íƒœì†Œ ë¶„ì„ê¸°) |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ì‹¤ìŠµ ì¤€ë¹„í•˜ê¸°\n",
                "ë¨¼ì € í•„ìš”í•œ ë„êµ¬ë“¤ì„ ì„¤ì¹˜í•˜ê³  ë¶ˆëŸ¬ì™€ë³´ì."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "NLTK version: 3.9.2\n"
                    ]
                }
            ],
            "source": [
                "# NLTK(Natural Language Toolkit) ë¶ˆëŸ¬ì˜¤ê¸°\n",
                "import nltk\n",
                "\n",
                "# ì˜ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ ë²„ì „ í•œë²ˆ í™•ì¸í•´ë³¼ê¹Œ?\n",
                "print(f\"NLTK version: {nltk.__version__}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ“¥ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
                "NLTKëŠ” ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ìˆì–´ì„œ, í•„ìš”í•œ ê²ƒë§Œ ê³¨ë¼ì„œ ë‹¤ìš´ë¡œë“œ ë°›ì•„ì•¼ í•´.\n",
                "- `punkt`: ë¬¸ì¥ì„ ë‹¨ì–´ë¡œ ìª¼ê°œì£¼ëŠ”(í† í°í™”) ëª¨ë¸\n",
                "- `stopwords`: ë¶„ì„ì— ë°©í•´ë˜ëŠ” í”í•œ ë‹¨ì–´ë“¤(ë¶ˆìš©ì–´) ëª©ë¡"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
                        "[nltk_data] Downloading package punkt_tab to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "True"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "nltk.download('punkt')         # í† í°í™”(Punkt) ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ\n",
                "nltk.download('punkt_tab')     # Punkt ê´€ë ¨ ì¶”ê°€ ë¦¬ì†ŒìŠ¤\n",
                "nltk.download('stopwords')     # ë¶ˆìš©ì–´(Stopwords) ëª©ë¡ ë‹¤ìš´ë¡œë“œ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. í† í°í™” (Tokenization): í…ìŠ¤íŠ¸ ì¡°ê°ë‚´ê¸° ğŸ”ª\n",
                "\n",
                "> **\"ìš”ë¦¬ì˜ ì‹œì‘ì€ ì¬ë£Œ ì†ì§ˆë¶€í„°!\"**\n",
                "\n",
                "ê¸´ ê¸€ì„ ë¶„ì„í•˜ë ¤ë©´ ë¨¼ì € ì‘ê²Œ ìª¼ê°œì•¼ í•´. ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ, í˜¹ì€ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ **í† í°í™”(Tokenization)**ë¼ê³  í•´.\n",
                "\n",
                "- **Sent Tokenize**: ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸° (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ ê¸°ì¤€)\n",
                "- **Word Tokenize**: ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìë¥´ê¸° (ë„ì–´ì“°ê¸° ê¸°ì¤€)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ë‹¨ì–´ í† í°í™” ê²°ê³¼: ['NLTK', 'is', 'a', 'powerful', 'library', 'for', 'NLP', '!', '!', '!', '!', '!']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.tokenize import word_tokenize, sent_tokenize    # í† í°í™” í•¨ìˆ˜ë“¤ ë¶ˆëŸ¬ì˜¤ê¸°\n",
                "\n",
                "# ì˜ˆì‹œ ë¬¸ì¥\n",
                "text = \"NLTK is a powerful library for NLP!!!!!\"\n",
                "\n",
                "# ë‹¨ì–´ í† í°í™” ì‹¤í–‰\n",
                "tokens = word_tokenize(text)\n",
                "print(\"ë‹¨ì–´ í† í°í™” ê²°ê³¼:\", tokens)\n",
                "# ê²°ê³¼: ['NLTK', 'is', 'a', ..., '!!!!!'] -> ëŠë‚Œí‘œê¹Œì§€ ë”°ë¡œ ë–¨ì–´ì§€ëŠ” ê±¸ ë³¼ ìˆ˜ ìˆì–´!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì´ ë¬¸ì¥ ê°œìˆ˜: 3ê°œ\n",
                        "ë¬¸ì¥ í† í°í™” ê²°ê³¼: ['The Matrix is everywhere its all around us, here even in this room.', 'You can see it out your window or on your television.', 'You feel it when you go to work, or go to church or pay your taxes.']\n"
                    ]
                }
            ],
            "source": [
                "# ì˜í™” 'ë§¤íŠ¸ë¦­ìŠ¤'ì˜ ëŒ€ì‚¬ì•¼. ë¬¸ì¥ì´ ì—¬ëŸ¬ ê°œ ì„ì—¬ìˆì–´.\n",
                "multi_sent_text = '''The Matrix is everywhere its all around us, here even in this room.\n",
                "You can see it out your window or on your television.\n",
                "You feel it when you go to work, or go to church or pay your taxes.'''\n",
                "\n",
                "# ë¬¸ì¥ í† í°í™” ì‹¤í–‰\n",
                "sentences = sent_tokenize(multi_sent_text)\n",
                "\n",
                "print(f\"ì´ ë¬¸ì¥ ê°œìˆ˜: {len(sentences)}ê°œ\")\n",
                "print(\"ë¬¸ì¥ í† í°í™” ê²°ê³¼:\", sentences)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ§© N-gram: ë‹¨ì–´ ì§ê¿ ì°¾ê¸°\n",
                "ë‹¨ì–´ë¥¼ í•˜ë‚˜ì”©ë§Œ ë³´ë©´ ì˜ë¯¸ê°€ ëŠê¸¸ ë•Œê°€ ìˆì–´. \"New York\"ì„ \"New\"ì™€ \"York\"ë¡œ ë”°ë¡œ ë³´ë©´ ì´ìƒí•˜ì–ì•„?\n",
                "ê·¸ë˜ì„œ ë‹¨ì–´ë¥¼ 2ê°œ, 3ê°œì”© ë¬¶ì–´ì„œ ë³´ëŠ” ë°©ë²•ì„ **N-gram**ì´ë¼ê³  í•´.\n",
                "\n",
                "- **Bi-gram (2-gram)**: 2ê°œì”© ë¬¶ê¸°\n",
                "- **Tri-gram (3-gram)**: 3ê°œì”© ë¬¶ê¸°"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Bi-gram: [('The', 'Matrix'), ('Matrix', 'is'), ('is', 'everywhere'), ('everywhere', 'its'), ('its', 'all'), ('all', 'around'), ('around', 'us')]\n",
                        "Tri-gram: [('The', 'Matrix', 'is'), ('Matrix', 'is', 'everywhere'), ('is', 'everywhere', 'its'), ('everywhere', 'its', 'all'), ('its', 'all', 'around'), ('all', 'around', 'us')]\n"
                    ]
                }
            ],
            "source": [
                "from nltk import ngrams    # n-gram ìƒì„± ë„êµ¬\n",
                "\n",
                "# ìœ„ì—ì„œ ìë¥¸ ë‹¨ì–´ë“¤(tokens)ì„ ì¬ë£Œë¡œ ì‚¬ìš©í•´\n",
                "tokens = word_tokenize(\"The Matrix is everywhere its all around us\")\n",
                "\n",
                "# Bi-gram (2ê°œì”© ë¬¶ê¸°)\n",
                "bigram = list(ngrams(tokens, 2))\n",
                "print(\"Bi-gram:\", bigram)\n",
                "\n",
                "# Tri-gram (3ê°œì”© ë¬¶ê¸°)\n",
                "trigram = list(ngrams(tokens, 3))\n",
                "print(\"Tri-gram:\", trigram)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ë¶ˆìš©ì–´ ì œê±° (Stopwords Removal): ì°Œêº¼ê¸° ë²„ë¦¬ê¸° ğŸ—‘ï¸\n",
                "\n",
                "> **\"ì½©ë‚˜ë¬¼ ë¨¸ë¦¬ì™€ ê¼¬ë¦¬ë¥¼ ë‹¤ë“¬ë“¯ì´\"**\n",
                "\n",
                "`a`, `the`, `is`, `of` ê°™ì€ ë‹¨ì–´ë“¤ì€ ë¬¸ë²•ì ìœ¼ë¡œëŠ” ì¤‘ìš”í•˜ì§€ë§Œ, **í‚¤ì›Œë“œ ë¶„ì„**í•  ë•ŒëŠ” ë°©í•´ë§Œ ë¼.\n",
                "ì´ëŸ° ë‹¨ì–´ë“¤ì„ **ë¶ˆìš©ì–´(Stopword)**ë¼ê³  ë¶€ë¥´ê³ , ê³¼ê°í•˜ê²Œ ì§€ì›Œë²„ë¦¬ëŠ” ê²Œ ì¢‹ì•„."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì˜ì–´ ë¶ˆìš©ì–´ ê°œìˆ˜: 198ê°œ\n",
                        "ì˜ˆì‹œ 10ê°œ: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.corpus import stopwords           # ë¶ˆìš©ì–´ ì‚¬ì „\n",
                "\n",
                "# ì˜ì–´ì˜ ë¶ˆìš©ì–´ ëª©ë¡ì„ ê°€ì ¸ì™€ë³´ì\n",
                "stop_words_list = stopwords.words('english')\n",
                "print(f\"ì˜ì–´ ë¶ˆìš©ì–´ ê°œìˆ˜: {len(stop_words_list)}ê°œ\")\n",
                "print(\"ì˜ˆì‹œ 10ê°œ:\", stop_words_list[:10])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì›ë˜ ë‹¨ì–´ ìˆ˜: 15 -> ì œê±° í›„: 8\n",
                        "['matrix', 'everywhere', 'around', 'us', ',', 'even', 'room', '.']\n"
                    ]
                }
            ],
            "source": [
                "# ì‹¤ì œë¡œ ë¶ˆìš©ì–´ë¥¼ ì œê±°í•´ë³´ì!\n",
                "text = \"The Matrix is everywhere its all around us, here even in this room.\"\n",
                "word_tokens = word_tokenize(text)\n",
                "\n",
                "clean_tokens = []  # ê¹¨ë—í•œ ë‹¨ì–´ë“¤ì„ ë‹´ì„ ë¦¬ìŠ¤íŠ¸\n",
                "\n",
                "for word in word_tokens:\n",
                "    word = word.lower() # ì†Œë¬¸ìë¡œ ë³€í™˜ (The -> the)\n",
                "    if word not in stop_words_list:  # ë¶ˆìš©ì–´ ëª©ë¡ì— ì—†ìœ¼ë©´?\n",
                "        clean_tokens.append(word)    # clean_tokens ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€!\n",
                "\n",
                "print(f\"ì›ë˜ ë‹¨ì–´ ìˆ˜: {len(word_tokens)} -> ì œê±° í›„: {len(clean_tokens)}\")\n",
                "print(clean_tokens)\n",
                "# 'The', 'is', 'its', 'all', 'here', 'in', 'this' ë“±ì´ ì‚¬ë¼ì¡Œì„ ê±°ì•¼!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. í…ìŠ¤íŠ¸ ë²¡í„°í™” (Feature Vectorization)\n",
                "\n",
                "> **\"ê¸€ìë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ëŠ” ë§ˆë²•\"**\n",
                "\n",
                "ì»´í“¨í„°ëŠ” 'ì‚¬ë‘'ì´ë¼ëŠ” ë‹¨ì–´ì˜ ì˜ë¯¸ë¥¼ ëª°ë¼. ê·¸ëƒ¥ `love`ë¼ëŠ” ê¸°í˜¸ë¡œ ë³¼ ë¿ì´ì§€.\n",
                "ê·¸ë˜ì„œ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë°”ê¿”ì¤˜ì•¼ ë¨¸ì‹ ëŸ¬ë‹ì„ ëŒë¦´ ìˆ˜ ìˆì–´. ëŒ€í‘œì ì¸ ë‘ ê°€ì§€ ë°©ë²•ì„ ë°°ì›Œë³´ì.\n",
                "\n",
                "### 1ï¸âƒ£ BoW (Bag of Words) - ì¹´ìš´íŠ¸ ê¸°ë°˜\n",
                "- **ë¹„ìœ **: ì¥ë°”êµ¬ë‹ˆì— ë¬´ì—‡ì´ ë“¤ì—ˆëŠ”ì§€ ì„¸ëŠ” ê²ƒ.\n",
                "- \"ì‚¬ê³¼ê°€ 3ê°œ, ë°°ê°€ 1ê°œ\"ì²˜ëŸ¼ ë‹¨ì–´ì˜ **ë¹ˆë„(Count)**ë§Œ ì…‰ë‹ˆë‹¤. ìˆœì„œëŠ” ìƒê´€ ì•ˆ í•´!\n",
                "- ë„êµ¬: `CountVectorizer`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë¶„ì„í•  ë‘ ê°œì˜ ë¬¸ì„œ ì˜ˆì‹œ\n",
                "text1 = 'The Matrix is everywhere its all around us, here even in this room.'\n",
                "text2 = 'You take the blue pill and the story ends. You wake in your bed and believe whatever you want to believe.'\n",
                "\n",
                "corpus = [text1, text2]  # ë¬¸ì„œ ëª¨ìŒ(Corpus)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ë‹¨ì–´ ì‚¬ì „(ì–´ë–¤ ë‹¨ì–´ê°€ ëª‡ ë²ˆ ì¸ë±ìŠ¤ì¸ì§€):\n",
                        "['bed' 'believe' 'blue' 'ends' 'matrix' 'pill' 'room' 'story' 'wake'\n",
                        " 'want']\n",
                        "\n",
                        "ë³€í™˜ëœ ë²¡í„°(ê° ë‹¨ì–´ê°€ ëª‡ ë²ˆ ë‚˜ì™”ëŠ”ì§€):\n",
                        "[[0 0 0 0 1 0 1 0 0 0]\n",
                        " [1 2 1 1 0 1 0 1 1 1]]\n"
                    ]
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "\n",
                "# 1. ëª¨ë¸ ìƒì„± (ë¶ˆìš©ì–´ ì œê±° ì˜µì…˜ ì¶”ê°€)\n",
                "vectorizer = CountVectorizer(stop_words='english') # stop_wordsëŠ” ì‚¬ì´í‚·ëŸ° ë‚´ì¥ ê¸°ëŠ¥ì„\n",
                "\n",
                "# 2. í•™ìŠµ ë° ë³€í™˜ (Fit & Transform)\n",
                "# ë¬¸ì„œë¥¼ ì½ì–´ì„œ ë‹¨ì–´ ì‚¬ì „ì„ ë§Œë“¤ê³ (fit), ìˆ«ìë¡œ ë³€í™˜(transform)í•´\n",
                "bow_vectors = vectorizer.fit_transform(corpus)\n",
                "\n",
                "# 3. ê²°ê³¼ í™•ì¸\n",
                "print(\"ë‹¨ì–´ ì‚¬ì „(ì–´ë–¤ ë‹¨ì–´ê°€ ëª‡ ë²ˆ ì¸ë±ìŠ¤ì¸ì§€):\")\n",
                "print(vectorizer.get_feature_names_out()) # ì •ë ¬ëœ ë‹¨ì–´ ëª©ë¡\n",
                "\n",
                "print(\"\\në³€í™˜ëœ ë²¡í„°(ê° ë‹¨ì–´ê°€ ëª‡ ë²ˆ ë‚˜ì™”ëŠ”ì§€):\")\n",
                "print(bow_vectors.toarray())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ“Š DataFrameìœ¼ë¡œ ì˜ˆì˜ê²Œ ë³´ê¸°\n",
                "ìˆ«ìë¡œë§Œ ë³´ë©´ í—·ê°ˆë¦¬ë‹ˆê¹Œ, íŒë‹¤ìŠ¤ë¥¼ ì´ìš©í•´ì„œ í‘œë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ë³¼ê²Œ."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>bed</th>\n",
                            "      <th>believe</th>\n",
                            "      <th>blue</th>\n",
                            "      <th>ends</th>\n",
                            "      <th>matrix</th>\n",
                            "      <th>pill</th>\n",
                            "      <th>room</th>\n",
                            "      <th>story</th>\n",
                            "      <th>wake</th>\n",
                            "      <th>want</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>ë¬¸ì„œ1(Matrix)</th>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>ë¬¸ì„œ2(Pill)</th>\n",
                            "      <td>1</td>\n",
                            "      <td>2</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             bed  believe  blue  ends  matrix  pill  room  story  wake  want\n",
                            "ë¬¸ì„œ1(Matrix)    0        0     0     0       1     0     1      0     0     0\n",
                            "ë¬¸ì„œ2(Pill)      1        2     1     1       0     1     0      1     1     1"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "# í–‰(Row)ì€ ë¬¸ì„œ, ì—´(Column)ì€ ë‹¨ì–´ë“¤\n",
                "bow_df = pd.DataFrame(\n",
                "    bow_vectors.toarray(), \n",
                "    columns=vectorizer.get_feature_names_out(),\n",
                "    index=['ë¬¸ì„œ1(Matrix)', 'ë¬¸ì„œ2(Pill)']\n",
                ")\n",
                "\n",
                "bow_df"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2ï¸âƒ£ TF-IDF (Term Frequency - Inverse Document Frequency)\n",
                "\n",
                "- **ë¹„ìœ **: \"ì´ ìš”ë¦¬ì˜ ì£¼ì¸ê³µì€ ëˆ„êµ¬?\"\n",
                "- **TF (ë¹ˆë„)**: ë§ì´ ë‚˜ì˜¤ë©´ ì¤‘ìš”í•˜ë‹¤! (ê°€ì )\n",
                "- **IDF (ì—­ë¬¸ì„œ ë¹ˆë„)**: ê·¼ë° ê°œë‚˜ ì†Œë‚˜ ë‹¤ ì“°ëŠ” ë‹¨ì–´ë©´ ë³„ë¡œ ì•ˆ ì¤‘ìš”í•˜ë‹¤! (ê°ì )\n",
                "- ì¦‰, **\"íŠ¹ì • ë¬¸ì„œì—ì„œë§Œ ìì£¼ ë“±ì¥í•˜ëŠ” í¬ê·€í•œ ë‹¨ì–´\"**ì— ë†’ì€ ì ìˆ˜ë¥¼ ì£¼ëŠ” ë°©ì‹ì´ì•¼."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>bed</th>\n",
                            "      <th>believe</th>\n",
                            "      <th>blue</th>\n",
                            "      <th>ends</th>\n",
                            "      <th>matrix</th>\n",
                            "      <th>pill</th>\n",
                            "      <th>room</th>\n",
                            "      <th>story</th>\n",
                            "      <th>wake</th>\n",
                            "      <th>want</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>ë¬¸ì„œ1(Matrix)</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.71</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.71</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>ë¬¸ì„œ2(Pill)</th>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.6</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.00</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.3</td>\n",
                            "      <td>0.3</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             bed  believe  blue  ends  matrix  pill  room  story  wake  want\n",
                            "ë¬¸ì„œ1(Matrix)  0.0      0.0   0.0   0.0    0.71   0.0  0.71    0.0   0.0   0.0\n",
                            "ë¬¸ì„œ2(Pill)    0.3      0.6   0.3   0.3    0.00   0.3  0.00    0.3   0.3   0.3"
                        ]
                    },
                    "execution_count": 15,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "# 1. TF-IDF ëª¨ë¸ ìƒì„±\n",
                "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
                "\n",
                "# 2. ë³€í™˜\n",
                "tfidf_vectors = tfidf_vectorizer.fit_transform(corpus)\n",
                "\n",
                "# 3. DataFrameìœ¼ë¡œ ë³€í™˜í•´ì„œ ë³´ì (ì†Œìˆ˜ì ìœ¼ë¡œ ê°€ì¤‘ì¹˜ê°€ ê³„ì‚°ëœ ê±¸ ë³¼ ìˆ˜ ìˆì–´)\n",
                "tfidf_df = pd.DataFrame(\n",
                "    tfidf_vectors.toarray(),\n",
                "    columns=tfidf_vectorizer.get_feature_names_out(),\n",
                "    index=['ë¬¸ì„œ1(Matrix)', 'ë¬¸ì„œ2(Pill)']\n",
                ")\n",
                "\n",
                "tfidf_df.round(2)  # ì†Œìˆ˜ì  2ìë¦¬ê¹Œì§€ë§Œ ë°˜ì˜¬ë¦¼í•´ì„œ ê¹”ë”í•˜ê²Œ"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ (Pop Quiz)\n",
                "\n",
                "ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©ì„ ì˜ ì´í•´í–ˆëŠ”ì§€ í™•ì¸í•´ë´!\n",
                "\n",
                "**Q1. ë¬¸ì¥ì„ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œëŠ” ì‘ì—…ì„ ë¬´ì—‡ì´ë¼ê³  í• ê¹Œ?**\n",
                "1. ì •ê·œí™” (Normalization)\n",
                "2. í† í°í™” (Tokenization)\n",
                "3. ë²¡í„°í™” (Vectorization)\n",
                "\n",
                "**Q2. ë¶„ì„ì— ë„ì›€ì´ ë˜ì§€ ì•ŠëŠ” 'a', 'the', 'is' ê°™ì€ ë‹¨ì–´ë¥¼ ë¶€ë¥´ëŠ” ë§ì€?**\n",
                "1. ë¶ˆìš©ì–´ (Stopwords)\n",
                "2. ìœ ì˜ì–´ (Synonyms)\n",
                "3. í•µì‹¬ì–´ (Keywords)\n",
                "\n",
                "**Q3. TF-IDFì—ì„œ 'ëª¨ë“  ë¬¸ì„œì— ê³µí†µì ìœ¼ë¡œ ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´'ëŠ” ì¤‘ìš”ë„ê°€ ì–´ë–»ê²Œ ë ê¹Œ?**\n",
                "1. ë†’ì•„ì§„ë‹¤.\n",
                "2. ë‚®ì•„ì§„ë‹¤.\n",
                "3. ë³€í•˜ì§€ ì•ŠëŠ”ë‹¤.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**ì •ë‹µ**\n",
                "\n",
                "<details>\n",
                "<summary>í´ë¦­í•´ì„œ ì •ë‹µ í™•ì¸í•˜ê¸°</summary>\n",
                "\n",
                "1. **2ë²ˆ í† í°í™”** (ì¬ë£Œ ì†ì§ˆ!)\n",
                "2. **1ë²ˆ ë¶ˆìš©ì–´** (ë§›ì—†ëŠ” ê¼¬ë¦¬!)\n",
                "3. **2ë²ˆ ë‚®ì•„ì§„ë‹¤** (ë„ˆë¬´ í”í•˜ë©´ íŠ¹ì§•ì´ ì•„ë‹ˆë‹ˆê¹Œ!)\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
