{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ•µï¸â€â™‚ï¸ NLP íƒì • í›ˆë ¨ì†Œ: ì‹¤ì „ ì—°ìŠµ\n",
                "\n",
                "í™˜ì˜í•œë‹¤, ì‹ ì… íƒì •! ğŸ•µï¸\n",
                "ì§€ê¸ˆë¶€í„° ìë„¤ê°€ ë°°ìš´ NLP ê¸°ìˆ ì„ í™œìš©í•´ì„œ ì‚¬ê±´ì„ í•´ê²°í•´ë´ì•¼ê² ì–´.\n",
                "\n",
                "**ì˜¤ëŠ˜ì˜ ë¯¸ì…˜:**\n",
                "1. ì•”í˜¸ë¬¸(í…ìŠ¤íŠ¸)ì„ í•´ì²´í•˜ê³  (í† í°í™”)\n",
                "2. ê°€ì¥ ë§ì´ ë“±ì¥í•œ ì˜ì‹¬ ë‹¨ì–´ë¥¼ ì°¾ê³  (ë¹ˆë„ ë¶„ì„)\n",
                "3. ê·¸ ë‹¨ì–´ì˜ ë‹¤ë¥¸ ì´ë¦„(ë™ì˜ì–´)ê¹Œì§€ íŒŒì•…í•˜ë¼! (WordNet)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ë¯¸ì…˜ 1: ì•”í˜¸ë¬¸ í•´ì²´ (Tokenization) ğŸ”ª\n",
                "\n",
                "í˜„ì¥ì—ì„œ ì…ìˆ˜í•œ 3ê°œì˜ ë¬¸ì¥ì´ ìˆë‹¤. ì´ê±¸ ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‚±ë‚±ì´ ë¶„í•´í•´ë¼."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# ìˆ˜ì§‘ëœ ë¬¸ì¥ë“¤ (Corpus)\n",
                "corpus = [\n",
                "    \"The thief stole the blue diamond from the museum.\",\n",
                "    \"The police are looking for the thief everywhere.\",\n",
                "    \"The blue diamond is very expensive and rare.\"\n",
                "]\n",
                "\n",
                "# ğŸ’» ì§ì ‘ í•´ë³´ê¸°: ê³µë°±ì„ ê¸°ì¤€ìœ¼ë¡œ ë‹¨ì–´ë¥¼ ì˜ë¼ë³´ì (split í•¨ìˆ˜ í™œìš©)\n",
                "tokenized_corpus = [sentence.split() for sentence in corpus]\n",
                "\n",
                "print(\"ë¶„í•´ëœ ë¬¸ì¥ë“¤:\", tokenized_corpus)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ë¯¸ì…˜ 2: í•µì‹¬ ìš©ì˜ì ì°¾ê¸° (Frequency Analysis) ğŸ”\n",
                "\n",
                "ë²”ì£„ í˜„ì¥ì—ì„œ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëœ ë‹¨ì–´ê°€ ë¬´ì—‡ì¸ì§€ ì•Œì•„ë‚´ì•¼ í•œë‹¤.\n",
                "ëª¨ë“  ë‹¨ì–´ë¥¼ í•œ ê³³ì— ëª¨ìœ¼ê³ , ë¹ˆë„ìˆ˜ë¥¼ ì„¸ì–´ë³´ì.\n",
                "\n",
                "íŒíŠ¸: `collections` ëª¨ë“ˆì˜ `Counter`ë¥¼ ì“°ë©´ ì•„ì£¼ í¸í•´!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from collections import Counter\n",
                "\n",
                "# 1. 2ì°¨ì› ë¦¬ìŠ¤íŠ¸(ë¬¸ì¥ë³„ ë‹¨ì–´)ë¥¼ 1ì°¨ì› ë¦¬ìŠ¤íŠ¸(ì „ì²´ ë‹¨ì–´)ë¡œ í‰í‰í•˜ê²Œ í´ê¸°\n",
                "# (ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜ ë³µìŠµ!)\n",
                "flat_tokens = [word for sentence in tokenized_corpus for word in sentence]\n",
                "\n",
                "# 2. ë¹ˆë„ìˆ˜ ì„¸ê¸°\n",
                "word_freq = Counter(flat_tokens)\n",
                "\n",
                "print(\"ë‹¨ì–´ ë“±ì¥ íšŸìˆ˜:\", word_freq)\n",
                "\n",
                "# Tip: 'the'ê°€ ë„ˆë¬´ ë§ì´ ë‚˜ì˜¤ì§€? ì´ëŸ° ê±¸ ë¶ˆìš©ì–´(Stopwords)ë¼ê³  í–ˆì—ˆì§€!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ë¯¸ì…˜ 3: ë³„ëª…(ë™ì˜ì–´) ì¶”ì  (WordNet) ğŸ•¸ï¸\n",
                "\n",
                "ìš©ì˜ìê°€ ì´ë¦„ì„ ë°”ê¿€ ìˆ˜ë„ ìˆë‹¤. \n",
                "**\"bank\"** ë¼ëŠ” ë‹¨ì–´ê°€ í¬ì°©ë˜ì—ˆëŠ”ë°, ì´ê²Œ 'ì€í–‰'ì¸ì§€ 'ê°•ë‘‘'ì¸ì§€ í—·ê°ˆë¦°ë‹¤.\n",
                "WordNetì„ ì´ìš©í•´ ëª¨ë“  ê°€ëŠ¥í•œ ëœ»ì„ ì¡°íšŒí•´ë¼!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk.corpus import wordnet\n",
                "import nltk\n",
                "\n",
                "# í•„ìš”í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ\n",
                "nltk.download('wordnet')\n",
                "\n",
                "target_word = \"bank\"\n",
                "synsets = wordnet.synsets(target_word)\n",
                "\n",
                "print(f\"'{target_word}'ì˜ ê°€ëŠ¥í•œ ì˜ë¯¸ë“¤:\")\n",
                "for syn in synsets:\n",
                "    print(f\"- {syn.name()}: {syn.definition()}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ‰ í›ˆë ¨ ì¢…ë£Œ!\n",
                "\n",
                "ê³ ìƒí–ˆì–´, íƒì •! ì´ì œ ìë„¤ëŠ”:\n",
                "1. ë¬¸ìë¥¼ ìª¼ê°œê³  (í† í°í™”)\n",
                "2. ì¤‘ìš”í•œ ê±¸ ì°¾ê³  (ë¹ˆë„ ë¶„ì„)\n",
                "3. ì§„ì§œ ì˜ë¯¸ë¥¼ íŒŒì•…í•˜ëŠ” (WordNet)\n",
                "ê¸°ì´ˆ ëŠ¥ë ¥ì„ ê°–ì·„ì–´. ë‹¤ìŒ ì‚¬ê±´ í˜„ì¥(ì‹¤ì „ ë°ì´í„°)ìœ¼ë¡œ ì¶œë™í•´ë³´ì! ğŸš“"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
