{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "804f6679",
            "metadata": {},
            "source": [
                "# 01. ìˆœì°¨ ë°ì´í„°(Sequential Data)ì™€ RNN ê¸°ì´ˆ\n",
                "### ê³¼ëª©: NLP Sequence Modeling\n",
                "---\n",
                "\n",
                "## 1. ìˆœì°¨ ë°ì´í„°ë€? (ì‹œê°„ì˜ íë¦„ì´ ìˆëŠ” ë°ì´í„°)\n",
                "ìš°ë¦¬ê°€ ë‹¤ë£¨ëŠ” ëŒ€ë¶€ë¶„ì˜ ë°ì´í„°ëŠ” **ìˆœì„œ**ê°€ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
                "- **í…ìŠ¤íŠ¸**: \"ë‚˜ëŠ” ë°¥ì„ ë¨¹ëŠ”ë‹¤\" vs \"ë¨¹ëŠ”ë‹¤ ë°¥ì„ ë‚˜ëŠ”\" (ìˆœì„œê°€ ë‹¤ë¥´ë©´ ì˜ë¯¸ê°€ ì´ìƒí•´ì§)\n",
                "- **ì£¼ì‹**: ì–´ì œ ê°€ê²©ì´ ì˜¤ëŠ˜ ê°€ê²©ì— ì˜í–¥ì„ ë¯¸ì¹¨.\n",
                "- **ìŒì„±**: ì†Œë¦¬ì˜ íŒŒë™ì´ ì—°ì†ì ìœ¼ë¡œ ì´ì–´ì§.\n",
                "\n",
                "> ** í•µì‹¬**: \"ì•ì˜ ë‚´ìš©ì„ ì•Œì•„ì•¼ ë’¤ì˜ ë‚´ìš©ì„ ì´í•´í•  ìˆ˜ ìˆë‹¤!\" \n",
                "\n",
                "## 2. RNN (Recurrent Neural Network): \"ê¸°ì–µì„ ê°€ì§„ ì‹ ê²½ë§\"\n",
                "ê¸°ì¡´ì˜ ì‹ ê²½ë§(DNN, CNN)ì€ **\"ê±´ë§ì¦\"**ì´ ì‹¬í–ˆìŠµë‹ˆë‹¤. ì…ë ¥(ì‚¬ì§„) í•˜ë‚˜ë¥¼ ë³´ê³  ë‚˜ë©´ ë°”ë¡œ ê¹Œë¨¹ì—ˆì£ .\n",
                "í•˜ì§€ë§Œ RNNì€ **\"ë©”ëª¨ì¥(Hidden State)\"**ì„ ê°€ì§€ê³  ìˆì–´ì„œ, ì´ì „ ë‹¨ê³„ì˜ ì •ë³´ë¥¼ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ê²¨ì¤ë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ§  ë™ì‘ ì›ë¦¬ (ë¹„ìœ )\n",
                "- **ì§ˆë¬¸**: \"ì´ ì˜í™” ì •ë§ ...\"\n",
                "- **ì¼ë°˜ ì‹ ê²½ë§**: \"...\" (ì•ì— ë¬´ìŠ¨ ë§ì´ ìˆì—ˆëŠ”ì§€ ëª¨ë¦„)\n",
                "- **RNN**: \"'ì´' -> 'ì˜í™”' -> 'ì •ë§' ê¹Œì§€ ë“¤ì—ˆìœ¼ë‹ˆ, ë’¤ì—ëŠ” ê¸ì •ì ì¸ í˜•ìš©ì‚¬ê°€ ì˜¬ ê±°ì•¼!\"\n",
                "\n",
                "### âš ï¸ ì¹˜ëª…ì ì¸ ë‹¨ì  (ê¸°ìš¸ê¸° ì†Œë©¸)\n",
                "- ë¬¸ì¥ì´ ë„ˆë¬´ ê¸¸ì–´ì§€ë©´ ì•ì˜ ë‚´ìš©ì„ ê¹Œë¨¹ìŠµë‹ˆë‹¤.\n",
                "- **ë¹„ìœ **: \"ì² ìˆ˜ê°€ ì–´ì œ ë°¥ì„ ë¨¹ê³  ... (100ë§ˆë””) ... ê·¸ë˜ì„œ **ê·¸**ëŠ” ë°°ê°€ ë¶ˆë €ë‹¤.\" \n",
                "- ì—¬ê¸°ì„œ 'ê·¸'ê°€ ëˆ„êµ¬ì¸ì§€ RNNì€ ê¸°ì–µì„ ëª» í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. (ì´ê±¸ í•´ê²°í•œ ê²Œ LSTM!)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2",
            "metadata": {},
            "source": [
                "## 3. ì‹¤ìŠµ: PyTorchë¡œ RNN êµ¬ì¡° ì°ì–´ë³´ê¸°\n",
                "ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” RNN ë¸”ë¡ì´ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ì½”ë“œë¡œ í™•ì¸í•´ë´…ì‹œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76be4a4d",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "# --- [1] ë°ì´í„° ì¤€ë¹„ (ê°€ìƒì˜ ë¬¸ì¥) ---\n",
                "# ìƒí™©: 2ê°œì˜ ë¬¸ì¥ì´ ìˆê³ , ê° ë¬¸ì¥ì€ 3ê°œì˜ ë‹¨ì–´ë¡œ ë˜ì–´ ìˆìœ¼ë©°, ê° ë‹¨ì–´ëŠ” 4ê°œì˜ ìˆ«ìë¡œ í‘œí˜„ë¨\n",
                "batch_size = 2     # ë¬¸ì¥ 2ê°œ (Batch Size)\n",
                "seq_len = 3        # ë‹¨ì–´ 3ê°œ (Time Steps)\n",
                "input_size = 4     # ë‹¨ì–´ í•˜ë‚˜ë‹¹ íŠ¹ì§• 4ê°œ (Embedding Size)\n",
                "hidden_size = 5    # RNNì´ ê¸°ì–µí•  ë©”ëª¨ë¦¬ í¬ê¸° (Hidden Size)\n",
                "\n",
                "# ëœë¤ ë°ì´í„° ìƒì„± (ì…ë ¥)\n",
                "x = torch.randn(batch_size, seq_len, input_size)\n",
                "print(f\"ì…ë ¥ ë°ì´í„° í˜•íƒœ (B, T, F): {x.shape}\")\n",
                "\n",
                "# --- [2] RNN ëª¨ë¸ ë§Œë“¤ê¸° ---\n",
                "# batch_first=True: (ë°°ì¹˜, ì‹œê°„, íŠ¹ì§•) ìˆœì„œë¡œ ë°ì´í„°ë¥¼ ë°›ê² ë‹¤ëŠ” ëœ» (PyTorch ê¸°ë³¸ì€ ì‹œê°„, ë°°ì¹˜, íŠ¹ì§•ì„)\n",
                "rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
                "\n",
                "# --- [3] ì‹¤í–‰ (Forward) ---\n",
                "output, hidden = rnn(x)\n",
                "\n",
                "print(\"\\n--- ê²°ê³¼ í™•ì¸ ---\")\n",
                "print(f\"1. ì „ì²´ ì¶œë ¥ (Output): {output.shape} -> (ë°°ì¹˜, ì‹œê°„, ì€ë‹‰í¬ê¸°)\")\n",
                "print(\"   >> ê° ë‹¨ì–´ë¥¼ ì½ì„ ë•Œë§ˆë‹¤ ë±‰ì–´ë‚¸ ìƒê°ë“¤\")\n",
                "print(f\"2. ìµœì¢… ê¸°ì–µ (Hidden): {hidden.shape} -> (ì¸µê°œìˆ˜, ë°°ì¹˜, ì€ë‹‰í¬ê¸°)\")\n",
                "print(\"   >> ë¬¸ì¥ì„ ë‹¤ ì½ê³  ë‚˜ì„œ ë¨¸ë¦¿ì†ì— ë‚¨ì€ ë§ˆì§€ë§‰ ìš”ì•½ë³¸\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ì‹¤ì „: IMDB ì˜í™” ë¦¬ë·° ê°ì„± ë¶„ì„\n",
                "ì´ì œ ì§„ì§œ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ë†€ì•„ë´…ì‹œë‹¤.\n",
                "**\"ì´ ì˜í™” ì§„ì§œ ì¬ë°Œë‹¤\"** -> **ê¸ì •(1)**\n",
                "**\"ëˆ ì•„ê¹ë‹¤\"** -> **ë¶€ì •(0)**\n",
                "\n",
                "ì´ê±¸ ë§ì¶”ëŠ” ëª¨ë¸ì„ RNNìœ¼ë¡œ ë§Œë“¤ì–´ë³¼ ê²ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "06daedc1",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.datasets import imdb\n",
                "import torch\n",
                "\n",
                "# --- [1] ë°ì´í„° ë¡œë“œ ---\n",
                "# num_words=300: ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ë‹¨ì–´ 300ê°œë§Œ ì‚¬ìš©í•˜ê² ë‹¤. (ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œ)\n",
                "vocab_size = 300\n",
                "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
                "\n",
                "print(f\"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê°œ\")\n",
                "\n",
                "# ë°ì´í„° ì¤„ì´ê¸° (ì‹¤ìŠµ ì†ë„ë¥¼ ìœ„í•´)\n",
                "X_train, y_train = X_train[:15000], y_train[:15000]\n",
                "X_test, y_test = X_test[:10000], y_test[:10000]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a15b1e95",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ëˆˆìœ¼ë¡œ í™•ì¸í•´ë³´ì\n",
                "print(\"--- ì²« ë²ˆì§¸ ë¦¬ë·° ë°ì´í„° (ìˆ«ìë¡œ ë³€í™˜ëœ ìƒíƒœ) ---\")\n",
                "print(X_train[0][:20], \"... (ë’¤ì— ë” ìˆìŒ)\")\n",
                "print(f\"ë¼ë²¨: {y_train[0]} (1ì´ë©´ ê¸ì •, 0ì´ë©´ ë¶€ì •)\")\n",
                "\n",
                "# ì›ë˜ ì´ê±´ ì˜ì–´ ë¬¸ì¥ì´ì—ˆìŒ. ì˜ˆë¥¼ ë“¤ì–´ 1='START', 14='this', 22='film' ..."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4",
            "metadata": {},
            "source": [
                "### âš ï¸ ë¬¸ì œ ë°œìƒ: ë¬¸ì¥ ê¸¸ì´ê°€ ë‹¤ ë‹¤ë¥´ë‹¤!\n",
                "ì–´ë–¤ ë¦¬ë·°ëŠ” ì§§ê³ (\"ë…¸ì¼\"), ì–´ë–¤ ë¦¬ë·°ëŠ” ê¹ë‹ˆë‹¤.\n",
                "ì»´í“¨í„°ëŠ” í–‰ë ¬(Matrix) ê³„ì‚°ì„ í•´ì•¼ í•´ì„œ **ê¸¸ì´ë¥¼ ë˜‘ê°™ì´ ë§ì¶°ì¤˜ì•¼(Padding)** í•©ë‹ˆë‹¤.\n",
                "\n",
                "- ì§§ìœ¼ë©´ -> ë’¤ì— 0ì„ ì±„ìš´ë‹¤.\n",
                "- ê¸¸ë©´ -> 100ê°œê¹Œì§€ë§Œ ì“°ê³  ìë¥¸ë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "edbf8a86",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn.functional as F\n",
                "\n",
                "# --- [2] íŒ¨ë”© (ê¸¸ì´ ë§ì¶”ê¸°) ---\n",
                "seq_len = 100  # ëª¨ë“  ë¬¸ì¥ì„ 100ë‹¨ì–´ë¡œ í†µì¼\n",
                "\n",
                "def pad_sequences(sequences, max_len):\n",
                "    padded_list = []\n",
                "    for seq in sequences:\n",
                "        # 1. PyTorch í…ì„œë¡œ ë³€í™˜ (Long íƒ€ì…: ì •ìˆ˜)\n",
                "        seq_tensor = torch.tensor(seq, dtype=torch.long)\n",
                "        \n",
                "        # 2. ê¸¸ì´ ì¡°ì ˆ\n",
                "        if len(seq_tensor) < max_len:\n",
                "            # ëª¨ìë¼ë©´ ë’¤ì— 0 ì±„ìš°ê¸° (Padding)\n",
                "            # F.pad(ì…ë ¥, (ì™¼ìª½ì±„ì›€, ì˜¤ë¥¸ìª½ì±„ì›€), ê°’)\n",
                "            padded = F.pad(seq_tensor, (0, max_len - len(seq_tensor)), value=0)\n",
                "        else:\n",
                "            # ë„˜ì¹˜ë©´ ìë¥´ê¸° (Truncating)\n",
                "            padded = seq_tensor[:max_len]\n",
                "        \n",
                "        padded_list.append(padded)\n",
                "    \n",
                "    # ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ í° í…ì„œë¡œ í•©ì¹˜ê¸° (Stack)\n",
                "    return torch.stack(padded_list)\n",
                "\n",
                "X_train_padded = pad_sequences(X_train, seq_len)\n",
                "X_test_padded = pad_sequences(X_test, seq_len)\n",
                "\n",
                "print(f\"íŒ¨ë”©ëœ ë°ì´í„° í˜•íƒœ: {X_train_padded.shape} -> (ìƒ˜í”Œ15000ê°œ, ê¸¸ì´100)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "205de1b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [3] ì›-í•« ì¸ì½”ë”© (ì„ íƒ ì‚¬í•­) ---\n",
                "# ë‹¨ì–´ ë²ˆí˜¸(3)ë¥¼ ë²¡í„°([0, 0, 0, 1, 0, ...])ë¡œ ë°”ê¾¸ëŠ” ì‘ì—…\n",
                "# í•˜ì§€ë§Œ ë³´í†µì€ 'Embedding Layer'ë¥¼ ì“°ëŠ”ë°, ì—¬ê¸°ì„  RNN ì›ë¦¬ë¥¼ ë³´ë ¤ê³  ì›-í•«ì„ ì”€\n",
                "# (ë©”ëª¨ë¦¬ë¥¼ ë§ì´ ë¨¹ìœ¼ë‹ˆ ì£¼ì˜!)\n",
                "\n",
                "X_train_onehot = F.one_hot(X_train_padded, num_classes=vocab_size).float()\n",
                "X_test_onehot = F.one_hot(X_test_padded, num_classes=vocab_size).float()\n",
                "\n",
                "print(f\"ì›-í•« ë³€í™˜ í›„: {X_train_onehot.shape}\")\n",
                "# (15000ê°œ ë¬¸ì¥, 100ê°œ ë‹¨ì–´, ê° ë‹¨ì–´ëŠ” 300ì¹¸ì§œë¦¬ ë²¡í„°)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5",
            "metadata": {},
            "source": [
                "## 5. ëª¨ë¸ ì„¤ê³„: ë‚´ ìƒì•  ì²« RNN ëª¨ë¸\n",
                "\n",
                "êµ¬ì¡°ëŠ” ê°„ë‹¨í•©ë‹ˆë‹¤.\n",
                "1. **RNN**: ë¬¸ì¥ì„ ì½ê³  ê°ì •(Hidden State)ì„ ì¶”ì¶œí•œë‹¤.\n",
                "2. **Linear(FC)**: ì¶”ì¶œëœ ê°ì •ì„ 0ê³¼ 1 ì‚¬ì´ ì ìˆ˜ë¡œ ë°”ê¾¼ë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93188c10",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "\n",
                "class SimpleRNN(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
                "        super().__init__()\n",
                "        \n",
                "        # 1. RNN ì¸µ: ë¬¸ì¥ì„ ì½ëŠ” ëˆˆê³¼ ë‡Œ\n",
                "        self.rnn = nn.RNN(\n",
                "            input_size=input_dim,    # ë‹¨ì–´(ë²¡í„°)ì˜ í¬ê¸° (ì—¬ê¸°ì„  300)\n",
                "            hidden_size=hidden_dim,  # ê¸°ì–µì¥ì¹˜ í¬ê¸° (ë‡Œ ìš©ëŸ‰, ì—¬ê¸°ì„  8)\n",
                "            batch_first=True         # (ë°°ì¹˜, ì‹œê°„, íŠ¹ì§•) ìˆœì„œ ìœ ì§€\n",
                "        )\n",
                "        \n",
                "        # 2. ì¶œë ¥ ì¸µ: ê¸ì •/ë¶€ì • íŒë‹¨ (íŒì‚¬)\n",
                "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # x: (ë°°ì¹˜, 100, 300) -> ë¬¸ì¥ë“¤ì´ ë“¤ì–´ì˜´\n",
                "        \n",
                "        # RNN ì‹¤í–‰\n",
                "        # output: ëª¨ë“  ì‹œì ì˜ ê¸°ë¡ (ì˜ ì•ˆ ì”€)\n",
                "        # hidden: ë§ˆì§€ë§‰ ì‹œì ì˜ ê¸°ì–µ (ì´ê²Œ ì¤‘ìš”! ë¬¸ì¥ ì „ì²´ ìš”ì•½ë³¸)\n",
                "        output, hidden = self.rnn(x)\n",
                "        \n",
                "        # hiddenì€ (1, ë°°ì¹˜, ì€ë‹‰) 3ì°¨ì›ì´ë¯€ë¡œ, (ë°°ì¹˜, ì€ë‹‰) 2ì°¨ì›ìœ¼ë¡œ í´ì¤Œ\n",
                "        last_memory = hidden.squeeze(0)\n",
                "        \n",
                "        # ê¸ì •/ë¶€ì • ì ìˆ˜ ê³„ì‚°\n",
                "        score = self.fc(last_memory)\n",
                "        return score\n",
                "\n",
                "# ëª¨ë¸ ìƒì„±\n",
                "input_dim = vocab_size # 300\n",
                "hidden_dim = 8         # ë‡Œ ìš©ëŸ‰ (ì‘ê²Œ ì¡ìŒ)\n",
                "output_dim = 1         # ì ìˆ˜ í•˜ë‚˜ (ê¸ì •ì¼ í™•ë¥ )\n",
                "\n",
                "model = SimpleRNN(input_dim, hidden_dim, output_dim)\n",
                "print(\"RNN ëª¨ë¸ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6",
            "metadata": {},
            "source": [
                "## 6. í•™ìŠµ ì¤€ë¹„\n",
                "ì´ì œ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë„£ê³  í•™ìŠµ(Training) ì‹œí‚¬ ì°¨ë¡€ì…ë‹ˆë‹¤.\n",
                "- **Loss Function**: `BCEWithLogitsLoss` (ì´ì§„ ë¶„ë¥˜ ë¬¸ì œë‹ˆê¹Œ)\n",
                "- **Optimizer**: `Adam` (êµ­ë£°)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3b3642a6",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "import torch.optim as optim\n",
                "\n",
                "# 1. ë¼ë²¨(ì •ë‹µ)ë„ í…ì„œë¡œ ë³€í™˜\n",
                "y_train_tensor = torch.tensor(y_train).float().unsqueeze(1) # (15000, 1)\n",
                "y_test_tensor = torch.tensor(y_test).float().unsqueeze(1)\n",
                "\n",
                "# 2. ë°ì´í„°ì…‹ ë§Œë“¤ê¸° (ì…ë ¥ê³¼ ì •ë‹µì„ ë¬¶ìŒ)\n",
                "train_dataset = TensorDataset(X_train_onehot, y_train_tensor)\n",
                "test_dataset = TensorDataset(X_test_onehot, y_test_tensor)\n",
                "\n",
                "# 3. ë°ì´í„° ë¡œë” (ë°°ì¹˜ ë‹¨ìœ„ë¡œ êº¼ë‚´ì¤Œ)\n",
                "batch_size = 64\n",
                "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
                "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
                "\n",
                "# 4. ì„¤ì •\n",
                "criterion = nn.BCEWithLogitsLoss() # ì´ì§„ ë¶„ë¥˜ ì†ì‹¤í•¨ìˆ˜\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001) # ìµœì í™” ë„êµ¬\n",
                "\n",
                "print(\"ë°ì´í„°ì…‹ê³¼ í•™ìŠµ ë„êµ¬ ì¤€ë¹„ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8266f91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- [4] ì‹¤ì œ í•™ìŠµ ëŒë¦¬ê¸° ---\n",
                "num_epochs = 5\n",
                "\n",
                "print(\"í•™ìŠµ ì‹œì‘...\")\n",
                "for epoch in range(num_epochs):\n",
                "    model.train() # í•™ìŠµ ëª¨ë“œ\n",
                "    total_loss = 0\n",
                "    \n",
                "    for inputs, targets in train_loader:\n",
                "        # 1. ì˜ˆì¸¡\n",
                "        outputs = model(inputs)\n",
                "        \n",
                "        # 2. ì±„ì  (ì†ì‹¤ ê³„ì‚°)\n",
                "        loss = criterion(outputs, targets)\n",
                "        \n",
                "        # 3. ëª¨ë¸ ìˆ˜ì • (ì—­ì „íŒŒ)\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    avg_loss = total_loss / len(train_loader)\n",
                "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")\n",
                "\n",
                "print(\"í•™ìŠµ ë! (Lossê°€ ë–¨ì–´ì§€ê³  ìˆë‹¤ë©´ ì„±ê³µì…ë‹ˆë‹¤)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7",
            "metadata": {},
            "source": [
                "### ğŸŒŸ ì˜¤ëŠ˜ì˜ ê²°ë¡ \n",
                "1. **RNN**ì€ ì´ì „ ì •ë³´ë¥¼ ê¸°ì–µí•´ì„œ ë‹¤ìŒì„ ì˜ˆì¸¡í•œë‹¤.\n",
                "2. ì½”ë“œë¡œ êµ¬í˜„í•  ë•ŒëŠ” `nn.RNN`ì„ ì“°ë©´ ëœë‹¤.\n",
                "3. í•˜ì§€ë§Œ RNNì€ **ê¸¸ì´ê°€ ê¸¸ì–´ì§€ë©´ ê¹Œë¨¹ëŠ”ë‹¤(ê¸°ìš¸ê¸° ì†Œë©¸)**.\n",
                "4. ê·¸ë˜ì„œ ë‹¤ìŒ ì‹œê°„ì—ëŠ” ë” ë˜‘ë˜‘í•œ ê¸°ì–µë ¥ì„ ê°€ì§„ **LSTM**ì„ ë°°ìš¸ ê²ƒì´ë‹¤!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}