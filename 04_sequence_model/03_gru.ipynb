{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1",
            "metadata": {},
            "source": [
                "# 03. GRU (Gated Recurrent Unit): LSTMì˜ ë‹¤ì´ì–´íŠ¸ ë²„ì „\n",
                "### ê³¼ëª©: NLP Sequence Modeling\n",
                "---\n",
                "\n",
                "## 1. LSTMì´ ë„ˆë¬´ ë¬´ê±°ì›Œìš”!\n",
                "LSTMì€ ì„±ëŠ¥ì´ ì¢‹ì§€ë§Œ, ê³„ì‚°í•  ê²Œ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤.\n",
                "- ë¬¸(Gate)ì´ 3ê°œë‚˜ ìˆê³ (ë§ê°, ì…ë ¥, ì¶œë ¥), ê¸°ì–µ ì¥ì†Œë„ 2ê°œ(Hidden, Cell)ë‚˜ ë©ë‹ˆë‹¤.\n",
                "- í•™ìŠµ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ê³  ë©”ëª¨ë¦¬ë„ ë§ì´ ë¨¹ìŠµë‹ˆë‹¤.\n",
                "\n",
                "## 2. GRU: \"í•„ìš” ì—†ëŠ” ê±° ë¹¼ê³  í•©ì¹˜ì!\"\n",
                "2014ë…„, ì¡°ê²½í˜„ êµìˆ˜ë‹˜ íŒ€ì´ ì œì•ˆí•œ ëª¨ë¸ì…ë‹ˆë‹¤. LSTMì„ ë‹¨ìˆœí™”í•˜ë©´ì„œ ì„±ëŠ¥ì€ ìœ ì¹˜í–ˆìŠµë‹ˆë‹¤.\n",
                "- **ë‹¤ì´ì–´íŠ¸ ë¹„ë²•**:\n",
                "    1.  **ê²Œì´íŠ¸ í†µí•©**: ë§ê° ê²Œì´íŠ¸ + ì…ë ¥ ê²Œì´íŠ¸ -> **ì—…ë°ì´íŠ¸ ê²Œì´íŠ¸(Update Gate)** í•˜ë‚˜ë¡œ í•©ì¹¨.\n",
                "    2.  **ê¸°ì–µ í†µí•©**: Cell Stateë¥¼ ì—†ì• ê³  **Hidden State** í•˜ë‚˜ë¡œ í‰ì¹¨.\n",
                "    3.  **ì¶œë ¥ ê²Œì´íŠ¸ ì‚­ì œ**: ê·¸ëƒ¥ Hidden Stateë¥¼ ê·¸ëŒ€ë¡œ ë‚´ë³´ëƒ„.\n",
                "\n",
                "> **ê²°ë¡ **: \"LSTMë³´ë‹¤ êµ¬ì¡°ëŠ” í›¨ì”¬ ê°„ë‹¨í•œë° ì„±ëŠ¥ì€ ë¹„ìŠ·í•˜ë„¤? ì™„ì „ ì´ë“!\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3",
            "metadata": {},
            "source": [
                "## 3. ì‹¤ìŠµ: PyTorchë¡œ GRU ì¨ë³´ê¸°\n",
                "ì‚¬ìš©ë²•ì€ `nn.LSTM`ê³¼ ë¹„ìŠ·í•˜ì§€ë§Œ, **Cell Stateê°€ ì—†ë‹¤**ëŠ” ì ì´ ì¤‘ìš”í•©ë‹ˆë‹¤. (RNNì²˜ëŸ¼ Hiddenë§Œ ìˆìŒ)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "code1",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "# --- [1] ë°ì´í„° ì¤€ë¹„ ---\n",
                "batch_size = 2\n",
                "seq_len = 3\n",
                "input_size = 4\n",
                "hidden_size = 5\n",
                "\n",
                "x = torch.randn(batch_size, seq_len, input_size)\n",
                "print(f\"ì…ë ¥ ë°ì´í„°: {x.shape}\")\n",
                "\n",
                "# --- [2] GRU ëª¨ë¸ ìƒì„± ---\n",
                "# LSTMê³¼ ì„ ì–¸ ë°©ì‹ì€ ë˜‘ê°™ìŠµë‹ˆë‹¤.\n",
                "gru = nn.GRU(input_size, hidden_size, batch_first=True)\n",
                "\n",
                "# --- [3] ì‹¤í–‰ (Forward) ---\n",
                "# ì°¨ì´ì : ë¦¬í„´ê°’ì´ outputê³¼ hidden 2ê°œë¿ì´ë‹¤! (Cell State ì—†ìŒ)\n",
                "output, hidden = gru(x)\n",
                "\n",
                "print(\"\\n--- ê²°ê³¼ í™•ì¸ ---\")\n",
                "print(f\"Output: {output.shape} (ëª¨ë“  ì‹œì ì˜ ê¸°ì–µ)\")\n",
                "print(f\"Hidden State: {hidden.shape} (ìµœì¢… ê¸°ì–µ)\")\n",
                "print(\"Cell State: ì—†ìŒ! (ì‹¬í”Œí•˜ì£ ?)\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ì‹¤ì „: IMDB ê°ì„± ë¶„ì„ (ë‹¤ì´ì–´íŠ¸ ë²„ì „)\n",
                "ì½”ë“œëŠ” LSTMê³¼ 99% ë™ì¼í•©ë‹ˆë‹¤. ëª¨ë¸ë§Œ ë°”ê¿” ë¼ì›Œë´…ì‹œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.datasets import imdb\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬ëŠ” ì•ì—ì„œ í–ˆìœ¼ë¯€ë¡œ ë¹ ë¥´ê²Œ ë„˜ì–´ê°‘ë‹ˆë‹¤.\n",
                "vocab_size = 300\n",
                "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
                "X_train, y_train = X_train[:15000], y_train[:15000]\n",
                "X_test, y_test = X_test[:10000], y_test[:10000]\n",
                "\n",
                "seq_len = 100\n",
                "def pad_sequences(sequences, max_len):\n",
                "    padded_list = []\n",
                "    for seq in sequences:\n",
                "        seq_tensor = torch.tensor(seq, dtype=torch.long)\n",
                "        if len(seq_tensor) < max_len:\n",
                "            padded = F.pad(seq_tensor, (0, max_len - len(seq_tensor)), value=0)\n",
                "        else:\n",
                "            padded = seq_tensor[:max_len]\n",
                "        padded_list.append(padded)\n",
                "    return torch.stack(padded_list)\n",
                "\n",
                "X_train_padded = pad_sequences(X_train, seq_len)\n",
                "X_train_onehot = F.one_hot(X_train_padded, num_classes=vocab_size).float()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_gru",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "\n",
                "class GRUNet(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
                "        super().__init__()\n",
                "        # â˜… GRU ì‚¬ìš© â˜…\n",
                "        self.gru = nn.GRU(\n",
                "            input_size=input_dim, \n",
                "            hidden_size=hidden_dim, \n",
                "            batch_first=True\n",
                "        )\n",
                "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # GRUëŠ” ë°˜í™˜ê°’ì´ 2ê°œ (output, hidden)\n",
                "        output, hidden = self.gru(x)\n",
                "        \n",
                "        # ë§ˆì§€ë§‰ hiddenë§Œ ì‚¬ìš©\n",
                "        last_hidden = hidden[-1]\n",
                "        score = self.fc(last_hidden)\n",
                "        return score\n",
                "\n",
                "model = GRUNet(vocab_size, hidden_dim=16, output_dim=1)\n",
                "print(\"GRU ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (LSTMë³´ë‹¤ ê°€ë²¼ì›€)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "train_gru",
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•™ìŠµ ì½”ë“œ (ë™ì¼)\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "import torch.optim as optim\n",
                "\n",
                "y_train_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
                "train_dataset = TensorDataset(X_train_onehot, y_train_tensor)\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "model.train()\n",
                "print(\"GRU í•™ìŠµ ì‹œì‘...\")\n",
                "for epoch in range(3):\n",
                "    total_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        outputs = model(inputs)\n",
                "        loss = criterion(outputs, targets)\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "end",
            "metadata": {},
            "source": [
                "### ğŸŒŸ ì˜¤ëŠ˜ì˜ ê²°ë¡ \n",
                "1. **GRU**ëŠ” LSTMì˜ ë™ìƒì´ë‹¤. (êµ¬ì¡°ê°€ í›¨ì”¬ ê°„ë‹¨í•¨)\n",
                "2. ì„±ëŠ¥ì€ LSTMê³¼ ë¹„ìŠ·í•˜ë©´ì„œ í•™ìŠµ ì†ë„ëŠ” ë” ë¹ ë¥´ë‹¤.\n",
                "3. ë°ì´í„°ê°€ ì ì„ ë• GRUê°€ ìœ ë¦¬í•˜ê³ , ë°ì´í„°ê°€ ì•„ì£¼ ë§ìœ¼ë©´ LSTMì´ ìœ ë¦¬í•  ìˆ˜ë„ ìˆë‹¤."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}