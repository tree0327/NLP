{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "cc8d37bf",
            "metadata": {},
            "source": [
                "# 02. LSTM (Long Short-Term Memory): ì ˆëŒ€ ê¹Œë¨¹ì§€ ì•ŠëŠ” ê¸°ì–µë ¥\n",
                "### ê³¼ëª©: NLP Sequence Modeling\n",
                "---\n",
                "\n",
                "## 1. RNNì˜ í•œê³„ì™€ LSTMì˜ ë“±ì¥\n",
                "ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ **RNN**ì€ \"ê±´ë§ì¦\"ì´ ì‹¬í–ˆìŠµë‹ˆë‹¤.\n",
                "- **ìƒí™©**: ë¬¸ì¥ì´ 100ë‹¨ì–´ê°€ ë„˜ì–´ê°€ë©´, ë§¨ ì²« ë‹¨ì–´ë¥¼ ê¹Œë¨¹ì–´ë²„ë¦½ë‹ˆë‹¤.\n",
                "- **í•´ê²°ì±…**: \"ì¤‘ìš”í•œ ê±´ ì˜¤ë˜ ê¸°ì–µí•˜ê³ , ì“¸ë°ì—†ëŠ” ê±´ ë¹¨ë¦¬ ìŠì–´ë²„ë¦¬ì!\"\n",
                "\n",
                "## 2. LSTM í•µì‹¬ ì›ë¦¬: \"3ëª…ì˜ ìˆ˜ë¬¸ì¥ (Gates)\"\n",
                "LSTMì—ëŠ” ê¸°ì–µì„ ê´€ë¦¬í•˜ëŠ” 3ê°œì˜ ë¬¸(Gate)ì´ ìˆìŠµë‹ˆë‹¤.\n",
                "\n",
                "1.  **ë§ê° ê²Œì´íŠ¸ (Forget Gate)**: \"ì´ê±° ì“¸ëª¨ì—†ëŠ” ì •ë³´ë„¤? ë²„ë ¤!\" \n",
                "    - ì˜ˆ: 'ê·¸ëŠ” ì–´ì œ ë°¥ì„ ë¨¹ì—ˆë‹¤.' -> 'ì–´ì œ'ë¼ëŠ” ì •ë³´ëŠ” ì´ì œ í•„ìš” ì—†ìœ¼ë‹ˆ ì‚­ì œ.\n",
                "2.  **ì…ë ¥ ê²Œì´íŠ¸ (Input Gate)**: \"ì˜¤, ì´ê±° ì¤‘ìš”í•œ ì •ë³´ë„¤? ê¸°ì–µí•´!\"\n",
                "    - ì˜ˆ: 'ë‚´ì¼ì€ ì‹œí—˜ì´ë‹¤.' -> 'ì‹œí—˜'ì´ë¼ëŠ” ì •ë³´ëŠ” ì¤‘ìš”í•˜ë‹ˆ ì €ì¥.\n",
                "3.  **ì¶œë ¥ ê²Œì´íŠ¸ (Output Gate)**: \"ì§€ê¸ˆì€ ì´ ì •ë³´ë¥¼ ë‚´ë³´ë‚´ì!\"\n",
                "    - ì˜ˆ: ëˆ„ê°€ \"ì‹œí—˜ ì–¸ì œì•¼?\"ë¼ê³  ë¬¼ìœ¼ë©´ 'ë‚´ì¼'ì´ë¼ëŠ” ì •ë³´ë¥¼ êº¼ëƒ„.\n",
                "\n",
                "> **ê²°ë¡ **: LSTMì€ **Cell State(ì»¨ë² ì´ì–´ ë²¨íŠ¸)**ë¥¼ í†µí•´ ê¸°ì–µì„ ì•„ì£¼ ì˜¤ë«ë™ì•ˆ ìš´ë°˜í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2",
            "metadata": {},
            "source": [
                "## 3. ì‹¤ìŠµ: PyTorchë¡œ LSTM êµ¬ì¡° í™•ì¸í•˜ê¸°\n",
                "ì½”ë“œëŠ” RNNê³¼ ê±°ì˜ ë˜‘ê°™ìŠµë‹ˆë‹¤. ë‹¨ì§€ `nn.RNN` ëŒ€ì‹  `nn.LSTM`ì„ ì“¸ ë¿ì…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e671c4ca",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "\n",
                "# --- [1] ë°ì´í„° ì¤€ë¹„ ---\n",
                "batch_size = 2\n",
                "seq_len = 3\n",
                "input_size = 4\n",
                "hidden_size = 5\n",
                "\n",
                "x = torch.randn(batch_size, seq_len, input_size)\n",
                "print(f\"ì…ë ¥ ë°ì´í„°: {x.shape}\")\n",
                "\n",
                "# --- [2] LSTM ëª¨ë¸ ìƒì„± ---\n",
                "# batch_first=True: (ë°°ì¹˜, ì‹œê°„, íŠ¹ì§•)\n",
                "lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
                "\n",
                "# --- [3] ì‹¤í–‰ (Forward) ---\n",
                "# RNNê³¼ ë‹¤ë¥¸ ì : ë¦¬í„´ê°’ì´ í•˜ë‚˜ ë” ìˆë‹¤! (Cell State)\n",
                "# output: ë§¤ ì‹œì ì˜ ì¶œë ¥\n",
                "# hidden: ë‹¨ê¸° ê¸°ì–µ (Short-term Memory)\n",
                "# cell: ì¥ê¸° ê¸°ì–µ (Long-term Memory) -> ì´ê²Œ í•µì‹¬!\n",
                "output, (hidden, cell) = lstm(x)\n",
                "\n",
                "print(\"\\n--- ê²°ê³¼ í™•ì¸ ---\")\n",
                "print(f\"Output: {output.shape} (ëª¨ë“  ì‹œì ì˜ ì¶œë ¥)\")\n",
                "print(f\"Hidden State: {hidden.shape} (ìµœì¢… ë‹¨ê¸° ê¸°ì–µ)\")\n",
                "print(f\"Cell State: {cell.shape} (ìµœì¢… ì¥ê¸° ê¸°ì–µ) â˜…ì¤‘ìš”\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ì‹¤ì „: IMDB ê°ì„± ë¶„ì„ (ì—…ê·¸ë ˆì´ë“œ ë²„ì „)\n",
                "RNNë•Œì™€ ê°™ì€ ë°ì´í„°ë¥¼ ì“°ì§€ë§Œ, ì´ë²ˆì—” LSTMìœ¼ë¡œ ì„±ëŠ¥ì„ ë†’ì—¬ë´…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_data",
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.datasets import imdb\n",
                "import torch.nn.functional as F\n",
                "\n",
                "# 1. ë°ì´í„° ë¡œë“œ\n",
                "vocab_size = 300\n",
                "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
                "\n",
                "# 2. ë°ì´í„° ì¤„ì´ê¸° (ì‹¤ìŠµìš©)\n",
                "X_train, y_train = X_train[:15000], y_train[:15000]\n",
                "X_test, y_test = X_test[:10000], y_test[:10000]\n",
                "\n",
                "# 3. íŒ¨ë”© (ê¸¸ì´ ë§ì¶”ê¸°)\n",
                "seq_len = 100\n",
                "def pad_sequences(sequences, max_len):\n",
                "    padded_list = []\n",
                "    for seq in sequences:\n",
                "        seq_tensor = torch.tensor(seq, dtype=torch.long)\n",
                "        if len(seq_tensor) < max_len:\n",
                "            padded = F.pad(seq_tensor, (0, max_len - len(seq_tensor)), value=0)\n",
                "        else:\n",
                "            padded = seq_tensor[:max_len]\n",
                "        padded_list.append(padded)\n",
                "    return torch.stack(padded_list)\n",
                "\n",
                "X_train_padded = pad_sequences(X_train, seq_len)\n",
                "X_test_padded = pad_sequences(X_test, seq_len)\n",
                "\n",
                "# 4. ì›-í•« ì¸ì½”ë”©\n",
                "X_train_onehot = F.one_hot(X_train_padded, num_classes=vocab_size).float()\n",
                "X_test_onehot = F.one_hot(X_test_padded, num_classes=vocab_size).float()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "64822c9c",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch.nn as nn\n",
                "\n",
                "class LSTMNet(nn.Module):\n",
                "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
                "        super().__init__()\n",
                "        # LSTM ì¸µ ì„ ì–¸\n",
                "        self.lstm = nn.LSTM(\n",
                "            input_size=input_dim, \n",
                "            hidden_size=hidden_dim, \n",
                "            batch_first=True\n",
                "        )\n",
                "        # ì¶œë ¥ ì¸µ\n",
                "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
                "\n",
                "    def forward(self, x):\n",
                "        # LSTM ì‹¤í–‰\n",
                "        # output: ì „ì²´ ë¬¸ì¥ì˜ íë¦„\n",
                "        # hidden: ë‹¨ê¸° ê¸°ì–µ (ë§ˆì§€ë§‰ ìƒíƒœ)\n",
                "        # cell: ì¥ê¸° ê¸°ì–µ (ë§ˆì§€ë§‰ ìƒíƒœ)\n",
                "        output, (hidden, cell) = self.lstm(x)\n",
                "        \n",
                "        # ìš°ë¦¬ëŠ” 'ë§ˆì§€ë§‰ ë‹¨ê¸° ê¸°ì–µ(hidden)'ì„ ì¨ì„œ íŒë³„í•  ê²ë‹ˆë‹¤.\n",
                "        # hiddenì€ (ì¸µìˆ˜, ë°°ì¹˜, ì°¨ì›)ì´ë¯€ë¡œ ë§ˆì§€ë§‰ ì¸µ([-1])ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.\n",
                "        last_hidden = hidden[-1]\n",
                "        \n",
                "        # ê¸ì •/ë¶€ì • íŒë‹¨\n",
                "        score = self.fc(last_hidden)\n",
                "        return score\n",
                "\n",
                "# ëª¨ë¸ ìƒì„± (RNNë³´ë‹¤ hidden_sizeë¥¼ ì¢€ ë” í‚¤ì›Œë´„)\n",
                "model = LSTMNet(vocab_size, hidden_dim=16, output_dim=1)\n",
                "print(\"LSTM ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8266f91",
            "metadata": {},
            "outputs": [],
            "source": [
                "# í•™ìŠµ ì½”ë“œëŠ” RNNê³¼ ë™ì¼í•©ë‹ˆë‹¤.\n",
                "from torch.utils.data import TensorDataset, DataLoader\n",
                "import torch.optim as optim\n",
                "\n",
                "y_train_tensor = torch.tensor(y_train).float().unsqueeze(1)\n",
                "train_dataset = TensorDataset(X_train_onehot, y_train_tensor)\n",
                "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
                "\n",
                "criterion = nn.BCEWithLogitsLoss()\n",
                "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
                "\n",
                "print(\"LSTM í•™ìŠµ ì‹œì‘...\")\n",
                "model.train()\n",
                "for epoch in range(3): # 3 ì—í­ë§Œ ëŒë ¤ë´…ì‹œë‹¤\n",
                "    total_loss = 0\n",
                "    for inputs, targets in train_loader:\n",
                "        outputs = model(inputs)\n",
                "        loss = criterion(outputs, targets)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        total_loss += loss.item()\n",
                "    \n",
                "    print(f\"Epoch {epoch+1}, Loss: {total_loss/len(train_loader):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7",
            "metadata": {},
            "source": [
                "### ğŸŒŸ ì˜¤ëŠ˜ì˜ ê²°ë¡ \n",
                "1. **RNN**ì€ ì˜ ê¹Œë¨¹ëŠ”ë°, **LSTM**ì€ ì¥ê¸° ê¸°ì–µ(Cell State)ì´ ìˆì–´ì„œ ê¸´ ê¸€ë„ ì˜ ì´í•´í•œë‹¤.\n",
                "2. PyTorchì—ì„œëŠ” ê·¸ëƒ¥ `nn.RNN`ì„ `nn.LSTM`ìœ¼ë¡œë§Œ ë°”ê¾¸ë©´ ëœë‹¤.\n",
                "3. ì„±ëŠ¥ì€ í›¨ì”¬ ì¢‹ë‹¤!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}