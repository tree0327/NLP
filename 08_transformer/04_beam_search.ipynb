{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "beam_intro",
            "metadata": {},
            "source": [
                "# Beam Search (ë¹” ì„œì¹˜) ë””ì½”ë”©\n",
                "\n",
                "ë²ˆì—­ ëª¨ë¸ì´ ë‹¨ì–´ë¥¼ ë‚´ë±‰ëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤. ì–´ë–»ê²Œ ì„ íƒí•˜ëŠëƒì— ë”°ë¼ ë²ˆì—­ì˜ í’ˆì§ˆì´ ë‹¬ë¼ì§‘ë‹ˆë‹¤.\n",
                "\n",
                "## ğŸ”¦ ë¹„ìœ : ë¯¸ë¡œ ì°¾ê¸°\n",
                "ê¹œê¹œí•œ ë¯¸ë¡œì—ì„œ ì¶œêµ¬ë¥¼ ì°¾ëŠ”ë‹¤ê³  ìƒìƒí•´ë´…ì‹œë‹¤.\n",
                "\n",
                "1.  **Greedy Search (íƒìš•ì  íƒìƒ‰)**: **\"ê·¼ì‹œì•ˆì ì¸ ë“±ì‚°ê°\"**\n",
                "    - ê°ˆë¦¼ê¸¸ë§ˆë‹¤ ì§€ê¸ˆ ë‹¹ì¥ ì œì¼ ì¢‹ì•„ ë³´ì´ëŠ” ê¸¸ë¡œë§Œ ê°‘ë‹ˆë‹¤.\n",
                "    - ì¥ì : ë¹ ë¦…ë‹ˆë‹¤. ê³ ë¯¼ ì—†ì´ ì„±í¼ì„±í¼ ê°€ë‹ˆê¹Œìš”.\n",
                "    - ë‹¨ì : ì§€ê¸ˆ ë‹¹ì¥ì€ ì¢‹ì•„ ë³´ì˜€ëŠ”ë° ë‚˜ì¤‘ì— ë§‰ë‹¤ë¥¸ ê¸¸ì´ë‚˜ ë‚­ë– ëŸ¬ì§€ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•œ ë²ˆ ì„ íƒí•˜ë©´ ë˜ëŒì•„ì˜¤ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
                "\n",
                "2.  **Beam Search (ë¹” ì„œì¹˜)**: **\"ì—¬ëŸ¬ ëª…ì˜ ì •ì°°ëŒ€ (Scout Team)\"**\n",
                "    - í˜¼ì ê°€ì§€ ì•Šê³  **Këª…(Beam Width)**ì˜ ì •ì°°ëŒ€ë¥¼ ë™ì‹œì— ë³´ëƒ…ë‹ˆë‹¤.\n",
                "    - ê°ì ìê¸°ê°€ ìˆëŠ” ê³³ì—ì„œ ê°ˆ ìˆ˜ ìˆëŠ” ê¸¸ì„ ë‹¤ íƒìƒ‰í•´ë³´ê³ , ê·¸ ì¤‘ì—ì„œ **ê°€ì¥ ìœ ë§í•œ ê¸¸ ìƒìœ„ Kê°œ**ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë¦½ë‹ˆë‹¤.\n",
                "    - ì´ë ‡ê²Œ ê³„ì† Kê°œì˜ ìµœì  ê²½ë¡œë¥¼ ìœ ì§€í•˜ë©´ì„œ ì „ì§„í•©ë‹ˆë‹¤.\n",
                "    - ì¥ì : í˜¼ì ê°€ëŠ” ê²ƒë³´ë‹¤ í›¨ì”¬ ë” ì¢‹ì€ ê¸¸(ì •í™•í•œ ë¬¸ì¥)ì„ ì°¾ì„ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤.\n",
                "    - ë‹¨ì : ê³„ì‚°ëŸ‰ì´ ë§ì•„ì ¸ì„œ ì¡°ê¸ˆ ëŠë¦½ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "import_cell",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn.functional as F\n",
                "import torch.nn as nn"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "code_explain",
            "metadata": {},
            "source": [
                "### Beam Search êµ¬í˜„ êµ¬í˜„ (í•µì‹¬ ë¡œì§)\n",
                "\n",
                "1.  **ì´ˆê¸°í™”**: ì‹œì‘ í† í°(`<sos>`) í•˜ë‚˜ë¥¼ ê°€ì§„ ë¹”(ê²½ë¡œ) 1ê°œë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
                "2.  **í™•ì¥ (Expand)**: í˜„ì¬ ìœ ì§€í•˜ê³  ìˆëŠ” ëª¨ë“  ë¹”(ê²½ë¡œ)ì—ì„œ ë‹¤ìŒ ë‹¨ì–´ í›„ë³´ë“¤ì„ ëª¨ë‘ í¼ì³ë´…ë‹ˆë‹¤. (ë¹” ê°œìˆ˜ $\\times$ ë‹¨ì–´ì¥ í¬ê¸°)\n",
                "3.  **í‰ê°€ ë° ê°€ì§€ì¹˜ê¸° (Pruning)**: í™•ì¥ëœ ìˆ˜ë§ì€ ê²½ë¡œ ì¤‘ì—ì„œ **ì ìˆ˜(í™•ë¥ )ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ Kê°œ**ë§Œ ë‚¨ê¸°ê³  ë‚˜ë¨¸ì§€ëŠ” ë‹¤ ìë¦…ë‹ˆë‹¤.\n",
                "4.  **ë°˜ë³µ**: ë¬¸ì¥ì´ ëë‚  ë•Œ(`<eos>`)ê¹Œì§€ 2~3ë²ˆì„ ë°˜ë³µí•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "beam_search_simple",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Beam Search ê¸°ë³¸ í•¨ìˆ˜ (ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ê°„ì†Œí™” ë²„ì „)\n",
                "def beam_search(decoder, hidden, context, beam_width=3, max_length=10):\n",
                "    # ë¹” ì´ˆê¸°í™”: [ [í˜„ì¬ ì‹œí€€ìŠ¤ ë¦¬ìŠ¤íŠ¸], ëˆ„ì  ì ìˆ˜, í˜„ì¬ íˆë“  ìƒíƒœ ]\n",
                "    # ì²˜ìŒì—” ì•„ë¬´ê²ƒë„ ì—†ìœ¼ë‹ˆ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì™€ ì ìˆ˜ 1.0(í™•ë¥  100%)ë¡œ ì‹œì‘\n",
                "    sequences = [[[], 1.0, hidden]]\n",
                "    \n",
                "    for _ in range(max_length):      # ìµœëŒ€ ê¸¸ì´ë§Œí¼ ë°˜ë³µ\n",
                "        all_candidates = []          # ì´ë²ˆ í„´ì— í™•ì¥ëœ ëª¨ë“  í›„ë³´ë“¤ì„ ë‹´ì„ ê³³\n",
                "\n",
                "        # í˜„ì¬ ì‚´ì•„ë‚¨ì€ ë¹”(ê²½ë¡œ)ë“¤ì„ í•˜ë‚˜ì”© í™•ì¥\n",
                "        for seq, score, hidden in sequences:\n",
                "            # ë””ì½”ë” ì…ë ¥ ì¤€ë¹„ (ì§ì „ ë‹¨ì–´ê°€ ì…ë ¥ì´ ë¨, ì—†ìœ¼ë©´ 0)\n",
                "            last_token = seq[-1] if seq else 0\n",
                "            decoder_input = torch.tensor([last_token]) \n",
                "            \n",
                "            # ë””ì½”ë” í•œ ìŠ¤í… ì „ì§„! -> ë‹¤ìŒ ë‹¨ì–´ ë¡œì§“(output)ê³¼ ìƒˆë¡œìš´ ìƒíƒœ(hidden)\n",
                "            output, hidden = decoder(decoder_input, hidden, context)\n",
                "            \n",
                "            # í™•ë¥ (Softmax)ì„ êµ¬í•˜ê³  ìƒìœ„ K(beam_width)ê°œë§Œ ë½‘ìŒ\n",
                "            probs = F.softmax(output, dim=1)\n",
                "            top_probs, top_indices = torch.topk(probs, beam_width)\n",
                "\n",
                "            # ë½‘íŒ ìƒìœ„ Kê°œ í›„ë³´ë¥¼ ê°ê° ìƒˆë¡œìš´ ê²½ë¡œë¡œ ë§Œë“¦\n",
                "            for i in range(beam_width):\n",
                "                token = top_indices[0][i].item()      # ë‹¨ì–´ ID\n",
                "                prob = top_probs[0][i].item()         # ê·¸ ë‹¨ì–´ì¼ í™•ë¥ \n",
                "                \n",
                "                # ìƒˆ í›„ë³´ ìƒì„±: (ê²½ë¡œ ì¶”ê°€, ì ìˆ˜ ê°±ì‹ , ìƒíƒœ ë³´ì¡´)\n",
                "                candidate = [\n",
                "                    seq + [token],    # ê¸°ì¡´ ê²½ë¡œì— ìƒˆ ë‹¨ì–´ ë¶™ì„\n",
                "                    score * prob,     # í™•ë¥ ì€ ê³„ì† ê³±í•´ ë‚˜ê° (P(A,B) = P(A) * P(B))\n",
                "                    hidden            # ë‹¤ìŒ ìŠ¤í…ì„ ìœ„í•´ ìƒíƒœ ë³´ì¡´\n",
                "                ]\n",
                "                all_candidates.append(candidate)\n",
                "\n",
                "        # ëª¨ë“  í›„ë³´ë“¤ ì¤‘ ì ìˆ˜ê°€ ê°€ì¥ ë†’ì€ ìƒìœ„ Kê°œë§Œ ë‹¤ì‹œ ì„ ë°œ (ê°€ì§€ì¹˜ê¸°)\n",
                "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
                "    \n",
                "    # ë°˜ë³µì´ ëë‚˜ë©´ ê°€ì¥ ì ìˆ˜ ë†’ì€ 1ë“± ê²½ë¡œ ë°˜í™˜\n",
                "    return sequences[0][0]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "log_prob_explain",
            "metadata": {},
            "source": [
                "### âš ï¸ ê°œì„ : ë¡œê·¸ í™•ë¥  (Log Probability) ì‚¬ìš©\n",
                "í™•ë¥ ë¼ë¦¬ ê³„ì† ê³±í•˜ë©´($0.9 \\times 0.8 \\times 0.5...$) ê°’ì´ 0ì— ë„ˆë¬´ ê°€ê¹Œì›Œì ¸ì„œ ì»´í“¨í„°ê°€ ê³„ì‚°í•˜ê¸° í˜ë“¤ì–´ì§‘ë‹ˆë‹¤ (Underflow ë¬¸ì œ).\n",
                "ê·¸ë˜ì„œ **ë¡œê·¸(Log)**ë¥¼ ì·¨í•´ì„œ **'ê³±í•˜ê¸°'ë¥¼ 'ë”í•˜ê¸°'ë¡œ ë°”ê¿‰ë‹ˆë‹¤.**\n",
                "$$ \\log(A \\times B) = \\log(A) + \\log(B) $$\n",
                "ì´ë ‡ê²Œ í•˜ë©´ ê°’ì´ ì‘ì•„ì ¸ë„ ì•ˆì „í•˜ê²Œ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "beam_search_eos",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ê°œì„ ëœ Beam Search (<eos> ì²˜ë¦¬ + Log í™•ë¥  ì‚¬ìš©)\n",
                "def beam_search_eos(decoder, hidden, context, beam_width=3, max_length=10, sos_id=0, eos_id=2):\n",
                "    # (ì‹œí€€ìŠ¤, ë¡œê·¸ ì ìˆ˜ í•©, íˆë“  ìƒíƒœ)ë¡œ ì´ˆê¸°í™”\n",
                "    # ë¡œê·¸ í™•ë¥ ì´ë‹ˆê¹Œ ê³±ì…ˆì˜ í•­ë“±ì› 1(log 1 = 0)ì¸ 0.0ìœ¼ë¡œ ì‹œì‘\n",
                "    sequences = [([sos_id], 0.0, hidden)]\n",
                "\n",
                "    for _ in range(max_length):\n",
                "        all_candidates = []\n",
                "        \n",
                "        # í˜„ì¬ ë¹” í™•ì¥\n",
                "        for seq, score, h in sequences:\n",
                "            # ì´ë¯¸ ëë‚œ ë¬¸ì¥(<eos>)ì´ë©´ ë” ì´ìƒ í™•ì¥í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ í›„ë³´ì— ë„£ìŒ\n",
                "            if seq[-1] == eos_id:\n",
                "                all_candidates.append((seq, score, h))\n",
                "                continue\n",
                "\n",
                "            decoder_input = torch.tensor([seq[-1]])\n",
                "            output, h2 = decoder(decoder_input, h, context)\n",
                "\n",
                "            # Log Softmax ì‚¬ìš©\n",
                "            log_probs = F.log_softmax(output, dim=1)\n",
                "            top_logp, top_idx = torch.topk(log_probs, beam_width)\n",
                "\n",
                "            for i in range(beam_width):\n",
                "                tok = top_idx[0, i].item()\n",
                "                log_p = top_logp[0, i].item()\n",
                "                \n",
                "                cand = (\n",
                "                    seq + [tok],      # ì‹œí€€ìŠ¤ í™•ì¥\n",
                "                    score + log_p,    # ì ìˆ˜ëŠ” ë”í•˜ê¸°(ëˆ„ì )\n",
                "                    h2                # ë‹¤ìŒ íˆë“  ìƒíƒœ\n",
                "                )\n",
                "                all_candidates.append(cand)\n",
                "\n",
                "        # ìƒìœ„ Kê°œ ì„ ë°œ\n",
                "        sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
                "        \n",
                "        # ë§Œì•½ ì‚´ì•„ë‚¨ì€ ëª¨ë“  ë¹”ì´ <eos>ë¡œ ëë‚¬ë‹¤ë©´ ì¡°ê¸° ì¢…ë£Œ\n",
                "        if all(seq[-1] == eos_id for seq, _, _ in sequences):\n",
                "            break\n",
                "    \n",
                "    best_seq = sequences[0][0]\n",
                "    return best_seq"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "greedy_decode",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë¹„êµìš©: Greedy Decode (ë§¤ ìˆœê°„ 1ë“±ë§Œ ì„ íƒ)\n",
                "def greedy_decode(decoder, hidden, context, max_length=10, sos_id=0, eos_id=2):\n",
                "    seq = [sos_id]\n",
                "    h = hidden\n",
                "\n",
                "    for _ in range(max_length):\n",
                "        decoder_input = torch.tensor([seq[-1]])\n",
                "        output, h = decoder(decoder_input, h, context)\n",
                "\n",
                "        log_probs = F.log_softmax(output, dim=1)\n",
                "        # ê³ ë¯¼ ì—†ì´ ê°€ì¥ ë†’ì€ ê²ƒ 1ê°œ ì„ íƒ (argmax)\n",
                "        next_tok = torch.argmax(log_probs, dim=1).item()\n",
                "\n",
                "        seq.append(next_tok)\n",
                "        if next_tok == eos_id:\n",
                "            break\n",
                "    \n",
                "    return seq"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "mock_decoder",
            "metadata": {},
            "source": [
                "## í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ê°€ì§œ ë””ì½”ë” ì¤€ë¹„\n",
                "ìœ„ í•¨ìˆ˜ë“¤ì´ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ê°„ë‹¨í•œ LSTM ë””ì½”ë”ë¥¼ ë§Œë“¤ì–´ë´…ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "mock_class",
            "metadata": {},
            "outputs": [],
            "source": [
                "class InputFeedingDecoder(nn.Module):\n",
                "    def __init__(self, input_size, hidden_size, output_size):\n",
                "        super(InputFeedingDecoder, self).__init__()\n",
                "        self.embedding = nn.Embedding(output_size, input_size)\n",
                "        self.lstm = nn.LSTM(input_size + hidden_size, hidden_size)\n",
                "        self.fc = nn.Linear(hidden_size, output_size)\n",
                "\n",
                "    def forward(self, input, hidden, context):\n",
                "        embedded = self.embedding(input).unsqueeze(0)\n",
                "        # ì…ë ¥ì— ì´ì „ ë§¥ë½(Context)ì„ ê°™ì´ ë¶™ì—¬ì„œ ë„£ì–´ì¤Œ\n",
                "        lstm_input = torch.cat((embedded, context.unsqueeze(0)), dim=2)\n",
                "        \n",
                "        output, hidden = self.lstm(lstm_input, hidden)\n",
                "        output = self.fc(output.squeeze(0))\n",
                "        return output, hidden"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "run_test",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ë‹¨ì–´ ë§µí•‘ (ìˆ«ì -> ë‹¨ì–´)\n",
                "id2word = {0:\"<sos>\", 1:\"I\", 2:\"<eos>\", 3:\"like\", 4:\"bus\", 5:\".\", 15:\"apple\", 18:\"love\", 27:\"cat\"}\n",
                "\n",
                "def decode_ids(ids):\n",
                "    return \" \".join(id2word.get(i, \"<unk>\") for i in ids)\n",
                "\n",
                "# í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •\n",
                "decoder = InputFeedingDecoder(input_size=10, hidden_size=20, output_size=30)\n",
                "hidden = (torch.zeros(1, 1, 20), torch.zeros(1, 1, 20))\n",
                "context = torch.zeros(1, 20)\n",
                "\n",
                "# ì‹¤í–‰\n",
                "greedy_result = greedy_decode(decoder, hidden, context)\n",
                "beam_result = beam_search_eos(decoder, hidden, context, beam_width=3)\n",
                "\n",
                "print(f\"Greedy ê²°ê³¼: {greedy_result}\\n -> {decode_ids(greedy_result)}\")\n",
                "print(f\"Beam   ê²°ê³¼: {beam_result}\\n -> {decode_ids(beam_result)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary_md",
            "metadata": {},
            "source": [
                "### ê²°ë¡ \n",
                "- **Greedy**: ë¹ ë¥´ì§€ë§Œ, ê°€ë” ì—‰ëš±í•œ ë¬¸ì¥ì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
                "- **Beam**: ì—¬ëŸ¬ ê°€ëŠ¥ì„±ì„ ì—´ì–´ë‘ê³  ëê¹Œì§€ ê³ ë¯¼í•˜ê¸° ë•Œë¬¸ì—, **ë” ìì—°ìŠ¤ëŸ½ê³  ì •í™•í•œ ë²ˆì—­ë¬¸**ì„ ë§Œë“¤ í™•ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì‹¤ì œ ë²ˆì—­ê¸° ì„œë¹„ìŠ¤ëŠ” ëŒ€ë¶€ë¶„ Beam Searchë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}