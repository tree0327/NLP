{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a580b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b0c596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 데이터 준비\n",
    "corpus = [\"자연어 처리는 재미있다\", \"Python은 강력하다\"]\n",
    "labels = [0, 1]\n",
    "\n",
    "# 벡터화 및 분류\n",
    "vectorizer = CountVectorizer()        # Bow (빈도기반)\n",
    "X = vectorizer.fit_transform(corpus)  # 단어사전 학습 + word_index, index_word\n",
    "model = MultinomialNB()               # 단어 카운트 데이터에 적합\n",
    "model.fit(X, labels)\n",
    "\n",
    "# 예측\n",
    "print(model.predict(vectorizer.transform([\"Python이 재미있다\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3399ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mCNNClassifier\u001b[39;00m(nn.Module):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\torch\\__init__.py:2197\u001b[39m\n\u001b[32m   2185\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m condition, message\n\u001b[32m   2188\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   2189\u001b[39m \u001b[38;5;66;03m# Import most common subpackages\u001b[39;00m\n\u001b[32m   2190\u001b[39m \u001b[38;5;66;03m################################################################################\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2195\u001b[39m \n\u001b[32m   2196\u001b[39m \u001b[38;5;66;03m# needs to be before import torch.nn as nn to avoid circular dependencies\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2197\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# usort: skip\u001b[39;00m\n\u001b[32m   2198\u001b[39m     enable_grad \u001b[38;5;28;01mas\u001b[39;00m enable_grad,\n\u001b[32m   2199\u001b[39m     inference_mode \u001b[38;5;28;01mas\u001b[39;00m inference_mode,\n\u001b[32m   2200\u001b[39m     no_grad \u001b[38;5;28;01mas\u001b[39;00m no_grad,\n\u001b[32m   2201\u001b[39m     set_grad_enabled \u001b[38;5;28;01mas\u001b[39;00m set_grad_enabled,\n\u001b[32m   2202\u001b[39m )\n\u001b[32m   2204\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m   2205\u001b[39m     __config__ \u001b[38;5;28;01mas\u001b[39;00m __config__,\n\u001b[32m   2206\u001b[39m     __future__ \u001b[38;5;28;01mas\u001b[39;00m __future__,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2234\u001b[39m     xpu \u001b[38;5;28;01mas\u001b[39;00m xpu,\n\u001b[32m   2235\u001b[39m )\n\u001b[32m   2236\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msignal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m windows \u001b[38;5;28;01mas\u001b[39;00m windows\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moverrides\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m handle_torch_function, has_torch_function, is_tensor_like\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _size, _TensorOrTensors, _TensorOrTensorsOrGradEdge\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m forward_ad, functional, graph\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01manomaly_mode\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m detect_anomaly, set_detect_anomaly\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Function, NestedIOFunction\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\torch\\autograd\\graph.py:23\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mautograd\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvariable\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Variable\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_python_dispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TorchDispatchMode\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RemovableHandle\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:366\u001b[39m\n\u001b[32m    362\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m func(*args, **kwargs)\n\u001b[32m    365\u001b[39m \u001b[38;5;66;03m# Subtypes which have __tensor_flatten__ and __tensor_unflatten__.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m366\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mTensorWithFlatten\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mProtocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__tensor_flatten__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;129;43m@staticmethod\u001b[39;49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__tensor_unflatten__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43minner_tensors\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten_spec\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_size\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mouter_stride\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Playdata\\nlp\\nlp_venv\\Lib\\site-packages\\torch\\utils\\_python_dispatch.py:399\u001b[39m, in \u001b[36mTensorWithFlatten\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    392\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstorage_offset\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m: ...\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdim\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mint\u001b[39m: ...\n\u001b[32m    396\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    398\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m399\u001b[39m     dtype: \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtypes\u001b[49m._dtype,\n\u001b[32m    400\u001b[39m     non_blocking: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    401\u001b[39m     copy: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    402\u001b[39m     *,\n\u001b[32m    403\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    404\u001b[39m ) -> torch.Tensor: ...\n\u001b[32m    406\u001b[39m \u001b[38;5;129m@overload\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto\u001b[39m(\n\u001b[32m    408\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    413\u001b[39m     *,\n\u001b[32m    414\u001b[39m     memory_format: Optional[torch.memory_format] = \u001b[38;5;28;01mNone\u001b[39;00m,\n",
      "\u001b[31mAttributeError\u001b[39m: partially initialized module 'torch' has no attribute 'types' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_classes):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.conv = nn.Conv2d(1, 100, (3, embed_size))  # 3-gram 필터\n",
    "        self.fc = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).unsqueeze(1)  # 채널 추가 (B, T, E) -> (B, 1, T, E)\n",
    "        x = torch.relu(self.conv(x)).squeeze(3)  # (B, 100, T-2, 1) -> (B, 100, T-2)\n",
    "        x = torch.max(x, dim=2)[0]  # Max pooling -> (B, 100)\n",
    "        x = self.fc(x)  # (B, C)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b29f1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier  # One-Vs-Rest 래퍼 클래스(클래스별 이진분류)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 데이터 준비\n",
    "corpus = [\"자연어 처리는 재미있다\", \"Python은 강력하다\"]\n",
    "labels = [[1, 0], [0, 1]]  # 다중 레이블\n",
    "\n",
    "# 모델 정의\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "# 클래스별 이진분류기를 여러개 학습해 다중 레이블 예측하는 분류기\n",
    "model = OneVsRestClassifier(LogisticRegression())\n",
    "model.fit(X, labels)\n",
    "\n",
    "# 예측 : 클래스별 0/1 배열\n",
    "print(model.predict(vectorizer.transform([\"Python이 재미있다\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7767761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
