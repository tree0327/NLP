{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "b0fe13c3",
            "metadata": {},
            "source": [
                "# 01. ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ (Naive Bayes): í™•ë¥ ë¡œ ì°ëŠ” ë¶„ë¥˜ê¸°\n",
                "### ê³¼ëª©: NLP Text Classification\n",
                "---\n",
                "\n",
                "## 1. \"ìŠ¤íŒ¸ì¼ê¹Œ ì•„ë‹ê¹Œ?\" í™•ë¥ ë¡œ ë§í˜€ë³´ì!\n",
                "ë‚˜ì´ë¸Œ ë² ì´ì¦ˆëŠ” **ì¡°ê±´ë¶€ í™•ë¥ (Conditional Probability)**ì„ ì´ìš©í•´ ì •ë‹µì„ ì¶”ì¸¡í•˜ëŠ” ì•„ì£¼ ë¹ ë¥´ê³  ê°•ë ¥í•œ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n",
                "í…ìŠ¤íŠ¸ ë¶„ë¥˜(ìŠ¤íŒ¸ ë©”ì¼ í•„í„°ë§, ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ë“±)ì—ì„œ ì˜¤ë«ë™ì•ˆ ì‚¬ë‘ë°›ì•„ì™”ìŠµë‹ˆë‹¤.\n",
                "\n",
                "### ğŸ” í•µì‹¬ ì•„ì´ë””ì–´: ë² ì´ì¦ˆ ì •ë¦¬ (Bayes' Theorem)\n",
                "> \"Bë¼ëŠ” ì¦ê±°ê°€ ë‚˜ì™”ì„ ë•Œ, Aì¼ í™•ë¥ ì€?\"\n",
                "\n",
                "$P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}$\n",
                "\n",
                "- ì˜ˆì‹œ: ë©”ì¼ì— **\"ë¬´ë£Œ\"**ë¼ëŠ” ë‹¨ì–´ê°€ ë“¤ì–´ìˆì„ ë•Œ(B), ì´ ë©”ì¼ì´ **ìŠ¤íŒ¸(A)**ì¼ í™•ë¥ ì€?\n",
                "    - $P(\\text{ìŠ¤íŒ¸}|\\text{ë¬´ë£Œ}) = \\frac{P(\\text{ë¬´ë£Œ}|\\text{ìŠ¤íŒ¸}) \\times P(\\text{ìŠ¤íŒ¸})}{P(\\text{ë¬´ë£Œ})}$\n",
                "\n",
                "## 2. ì™œ \"ë‚˜ì´ë¸Œ(Naive, ìˆœì§„í•œ)\"ë¼ê³  ë¶€ë¥¼ê¹Œ?\n",
                "ì´ ì•Œê³ ë¦¬ì¦˜ì€ **\"ëª¨ë“  ë‹¨ì–´(íŠ¹ì§•)ê°€ ì„œë¡œ ë…ë¦½ì´ë‹¤\"**ë¼ê³  ì•„ì£¼ ìˆœì§„í•˜ê²Œ ê°€ì •í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
                "- ì‹¤ì œë¡œëŠ” 'í™ ê¸¸ë™' ì²˜ëŸ¼ ë‹¨ì–´ë¼ë¦¬ ì—°ê´€ì´ ìˆì§€ë§Œ, ë‚˜ì´ë¸Œ ë² ì´ì¦ˆëŠ” 'í™'ê³¼ 'ê¸¸ë™'ì´ ì „í˜€ ìƒê´€ì—†ì´ ë”°ë¡œë”°ë¡œ ë“±ì¥í–ˆë‹¤ê³  ì¹©ë‹ˆë‹¤.\n",
                "- **ì¥ì **: ê³„ì‚°ì´ ì—„ì²­ë‚˜ê²Œ ë‹¨ìˆœí•´ì§€ê³  ë¹¨ë¼ì§‘ë‹ˆë‹¤. ê·¸ëŸ°ë°ë„ ì„±ëŠ¥ì€ ê½¤ ì¢‹ìŠµë‹ˆë‹¤!\n",
                "\n",
                "## 3. ëŒ€í‘œì ì¸ 3ì´ì‚¬\n",
                "1. **Gaussian NB**: í‚¤, ëª¸ë¬´ê²Œ ê°™ì€ ì—°ì†ì ì¸ ìˆ«ì ë°ì´í„°ì¼ ë•Œ (ì •ê·œë¶„í¬ ê°€ì •)\n",
                "2. **Multinomial NB**: **í…ìŠ¤íŠ¸ ë°ì´í„°(ë‹¨ì–´ ë¹ˆë„ìˆ˜)** ì²˜ëŸ¼ íšŸìˆ˜ê°€ ì¤‘ìš”í•  ë•Œ â˜…(ì˜¤ëŠ˜ ë°°ìš¸ ê²ƒ)\n",
                "3. **Bernoulli NB**: ìˆë‹¤/ì—†ë‹¤(0 ë˜ëŠ” 1) ê°™ì€ ì´ì§„ ë°ì´í„°ì¼ ë•Œ\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba98cbb0",
            "metadata": {},
            "source": [
                "---\n",
                "## 4. ì‹¤ìŠµ 1: ì•„ì£¼ ê°„ë‹¨í•œ ê°ì„± ë¶„ì„ (ê¸ì • vs ë¶€ì •)\n",
                "ë°ì´í„°ê°€ ì•„ì£¼ ì‘ì„ ë•Œ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ë´…ì‹œë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8378b32b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.feature_extraction.text import CountVectorizer\n",
                "from sklearn.naive_bayes import MultinomialNB\n",
                "import pandas as pd\n",
                "\n",
                "# 1. ì´ˆë¯¸ë‹ˆ ë°ì´í„°ì…‹\n",
                "texts = [\n",
                "    \"I love this movie\",      # ê¸ì •\n",
                "    \"This film was amazing\",  # ê¸ì •\n",
                "    \"I hate this movie\",      # ë¶€ì •\n",
                "    \"This movie was terrible\" # ë¶€ì • (ì˜¤íƒ€ ìˆ˜ì •ë¨: moive -> movie)\n",
                "]\n",
                "labels = [\"pos\", \"pos\", \"neg\", \"neg\"]\n",
                "\n",
                "# 2. BoW (Bag of Words) ë§Œë“¤ê¸°\n",
                "# í…ìŠ¤íŠ¸ë¥¼ ìˆ«ì(ë‹¨ì–´ ë“±ì¥ íšŸìˆ˜)ë¡œ ë°”ê¿”ì•¼ ì»´í“¨í„°ê°€ ì´í•´í•©ë‹ˆë‹¤.\n",
                "vectorizer = CountVectorizer()\n",
                "X_train = vectorizer.fit_transform(texts)\n",
                "\n",
                "# ëˆˆìœ¼ë¡œ í™•ì¸í•´ë´…ì‹œë‹¤.\n",
                "print(\"--- ë‹¨ì–´ ì‚¬ì „ ---\")\n",
                "print(vectorizer.get_feature_names_out())\n",
                "print(\"\\n--- ë¬¸ì„œë¥¼ ìˆ«ìë¡œ ë°”ê¾¼ ê²°ê³¼ (í–‰:ë¬¸ì„œ, ì—´:ë‹¨ì–´) ---\")\n",
                "print(X_train.toarray())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3",
            "metadata": {},
            "source": [
                "## 5. ëª¨ë¸ í•™ìŠµ\n",
                "**MultinomialNB**ëŠ” \"ì´ ë‹¨ì–´ê°€ ë‚˜íƒ€ë‚¬ì„ ë•Œ ê¸ì •ì¼ í™•ë¥ ì´ ë†’ë‹ˆ, ë¶€ì •ì¼ í™•ë¥ ì´ ë†’ë‹ˆ?\"ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "065f9376",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
                "clf = MultinomialNB()\n",
                "clf.fit(X_train, labels)\n",
                "print(\"í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "823081af",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 6. ì˜ˆì¸¡í•´ë³´ê¸°\n",
                "test_text = [\"I love this movie\"] # í›ˆë ¨ ë°ì´í„°ì— ìˆë˜ ë¬¸ì¥ì´ì§€ë§Œ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¨ë´„\n",
                "\n",
                "# ì£¼ì˜: í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë°˜ë“œì‹œ í•™ìŠµ ë°ì´í„°(vectorizer)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.\n",
                "# fit_transform()ì´ ì•„ë‹ˆë¼ transform()ì„ ì”ë‹ˆë‹¤.\n",
                "X_test = vectorizer.transform(test_text)\n",
                "\n",
                "pred = clf.predict(X_test)\n",
                "print(f\"ë¬¸ì¥: '{test_text[0]}'\")\n",
                "print(f\"ì˜ˆì¸¡ ê²°ê³¼: {pred[0]} (ì •ë‹µ!)\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "49f9dc65",
            "metadata": {},
            "outputs": [],
            "source": [
                "# í™•ë¥ ë„ í™•ì¸í•´ë³¼ê¹Œìš”?\n",
                "proba = clf.predict_proba(X_test)\n",
                "classes = clf.classes_\n",
                "\n",
                "print(f\"í´ë˜ìŠ¤ ìˆœì„œ: {classes}\")\n",
                "print(f\"í™•ë¥  ë¶„í¬: {proba}\")\n",
                "# love ê°™ì€ ê¸ì • ë‹¨ì–´ê°€ ìˆì–´ì„œ pos í™•ë¥ ì´ ë” ë†’ê²Œ ë‚˜ì™”ì„ ê²ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dccfc85d",
            "metadata": {},
            "source": [
                "---\n",
                "## 7. ì‹¬í™”: ë‚´ë¶€ ë“¤ì—¬ë‹¤ë³´ê¸° (Log Probability)\n",
                "ë‚˜ì´ë¸Œ ë² ì´ì¦ˆëŠ” ì»´í“¨í„° ê³„ì‚° ë¬¸ì œ(Underflow)ë¥¼ ë§‰ê¸° ìœ„í•´ í™•ë¥ ì— **Log(ë¡œê·¸)**ë¥¼ ì”Œì›Œì„œ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
                "- í™•ë¥ ì€ 0~1 ì‚¬ì´ ê°’ì´ë¼ì„œ ê³„ì† ê³±í•˜ë©´ 0.00000...ìœ¼ë¡œ ì‚¬ë¼ì ¸ ë²„ë¦¬ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
                "- ë¡œê·¸ë¥¼ ì”Œìš°ë©´ ê³±í•˜ê¸°ê°€ ë”í•˜ê¸°ë¡œ ë°”ë€Œì–´ ê³„ì‚°ì´ í¸í•´ì§‘ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "40dcf292",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. í´ë˜ìŠ¤ë³„ ì‚¬ì „ í™•ë¥  (ë¡œê·¸ ê°’)\n",
                "# ë°ì´í„°ì…‹ì— ê¸ì • 2ê°œ, ë¶€ì • 2ê°œì˜€ìœ¼ë¯€ë¡œ í™•ë¥ ì€ 50:50 (0.5)\n",
                "# log(0.5) â‰ˆ -0.693\n",
                "print(f\"í´ë˜ìŠ¤ ì‚¬ì „ í™•ë¥  (Log): {clf.class_log_prior_}\")\n",
                "\n",
                "# 2. ë‹¨ì–´ë³„ ì¡°ê±´ë¶€ í™•ë¥  (ì´ ë‹¨ì–´ê°€ ê¸ì •/ë¶€ì •ì—ì„œ ë‚˜ì˜¬ í™•ë¥ )\n",
                "feature_log_prob = clf.feature_log_prob_\n",
                "\n",
                "# ë³´ê¸° ì¢‹ê²Œ í‘œë¡œ ë§Œë“¦\n",
                "df_prob = pd.DataFrame(\n",
                "    feature_log_prob,\n",
                "    columns=vectorizer.get_feature_names_out(),\n",
                "    index=clf.classes_\n",
                ")\n",
                "print(\"\\n--- ë‹¨ì–´ë³„ Log í™•ë¥  (ê°’ì´ í´ìˆ˜ë¡, ì¦‰ 0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¤‘ìš”í•œ ë‹¨ì–´) ---\")\n",
                "display(df_prob)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c7239508",
            "metadata": {},
            "source": [
                "---\n",
                "## 8. ì‹¤ì „: ë‰´ìŠ¤ê·¸ë£¹ ë¶„ë¥˜ (20 Newsgroups)\n",
                "ì¡°ê¸ˆ ë” ë³µì¡í•œ ë°ì´í„°ë¡œ ì‹¤í—˜í•´ë´…ì‹œë‹¤. ì£¼ì œê°€ ë‹¤ë¥¸ ìˆ˜ì²œ ê°œì˜ ë‰´ìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ë¶„ë¥˜í•©ë‹ˆë‹¤."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79ca6806",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.datasets import fetch_20newsgroups\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score, classification_report\n",
                "\n",
                "# 1. ë°ì´í„° ë¡œë“œ (ì‹œê°„ì´ ì¡°ê¸ˆ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\n",
                "print(\"ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n",
                "newsgroup = fetch_20newsgroups(subset='all')\n",
                "print(f\"ì´ ë¬¸ì„œ ê°œìˆ˜: {len(newsgroup.data)}\")\n",
                "\n",
                "# 2. TF-IDF ë³€í™˜\n",
                "# CountVectorizerë³´ë‹¤ ì¢€ ë” ë˜‘ë˜‘í•œ ë°©ì‹ (í”í•œ ë‹¨ì–´ íŒ¨ë„í‹° ì¤Œ)\n",
                "vectorizer = TfidfVectorizer(stop_words='english') # ì˜ì–´ ë¶ˆìš©ì–´(the, a ë“±) ì œê±°\n",
                "X = vectorizer.fit_transform(newsgroup.data)\n",
                "y = newsgroup.target\n",
                "\n",
                "print(f\"ë°ì´í„° í¬ê¸° (ë¬¸ì„œ, ë‹¨ì–´): {X.shape}\")\n",
                "\n",
                "# 3. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì…‹ ë¶„ë¦¬ (8:2)\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
                "print(\"ë°ì´í„° ë¶„ë¦¬ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "93ff5b3e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. ëª¨ë¸ í•™ìŠµ\n",
                "model = MultinomialNB()\n",
                "model.fit(X_train, y_train)\n",
                "print(\"ë‰´ìŠ¤ê·¸ë£¹ ë¶„ë¥˜ê¸° í•™ìŠµ ì™„ë£Œ!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a86954c8",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 5. ì„±ëŠ¥ í‰ê°€\n",
                "y_pred = model.predict(X_test)\n",
                "acc = accuracy_score(y_test, y_pred)\n",
                "\n",
                "print(f\"ì •í™•ë„: {acc:.4f}\")\n",
                "print(\"\\n--- ìƒì„¸ ë¦¬í¬íŠ¸ ---\")\n",
                "print(classification_report(y_test, y_pred, target_names=newsgroup.target_names))\n",
                "\n",
                "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆëŠ” ë”¥ëŸ¬ë‹ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ë©´ì„œë„ ê½¤ ì¤€ìˆ˜í•œ ì„±ëŠ¥(ì•½ 88%)ì„ ë³´ì—¬ì¤ë‹ˆë‹¤."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}