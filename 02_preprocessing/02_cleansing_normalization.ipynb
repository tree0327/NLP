{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ§¹ 2. ì •ì œ(Cleansing) & ì •ê·œí™”(Normalization): ì¬ë£Œ ì†ì§ˆí•˜ê¸°\n",
                "\n",
                "> **\"í™ ë¬»ì€ ë‹¹ê·¼ì„ ì”»ê³ , ê»ì§ˆì„ ê¹Œì•¼ ìš”ë¦¬ë¥¼ í•˜ì§€!\"**\n",
                "\n",
                "í† í°í™”ê°€ 'ì¬ë£Œë¥¼ ì¨ëŠ” ê²ƒ'ì´ë¼ë©´, ì´ë²ˆ ë‹¨ê³„ëŠ” **'ëª» ë¨¹ëŠ” ê²ƒ(ë¶ˆìˆœë¬¼)ì„ ë²„ë¦¬ëŠ”'** ê³¼ì •ì´ì•¼.\n",
                "ë°ì´í„°ê°€ ë”ëŸ¬ìš°ë©´ AI ì„±ëŠ¥ë„ ì—‰ë§ì´ ë˜ê±°ë“ . (GIGO: Garbage In, Garbage Out ğŸ—‘ï¸)\n",
                "\n",
                "### ğŸ¯ ì˜¤ëŠ˜ì˜ í•  ì¼\n",
                "1. **ê·œì¹™ ê¸°ë°˜ ì •ê·œí™”**: `US`ë‘ `USA`ëŠ” ê°™ì€ ê±°ì–ì•„? í†µì¼ì‹œí‚¤ì!\n",
                "2. **ëŒ€ì†Œë¬¸ì í†µí•©**: `Apple`ì´ë‘ `apple`ì€ ê°™ì€ ì‚¬ê³¼ì•¼.\n",
                "3. **ë¶ˆìš©ì–´ ì œê±°**: `the`, `is`, `a` ì²˜ëŸ¼ ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ë²„ë¦¬ê¸°."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ê·œì¹™ ê¸°ë°˜ ì •ê·œí™” & ëŒ€ì†Œë¬¸ì í†µí•© ğŸ“\n",
                "\n",
                "ì‚¬ëŒë“¤ì´ íƒ€ì´í•‘ì„ ì œë©‹ëŒ€ë¡œ í•˜ë‹ˆê¹Œ, ìš°ë¦¬ê°€ ê°•ì œë¡œ í†µì¼ì‹œì¼œì¤˜ì•¼ í•´."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì›ë³¸: The United Kingdom and UK have a long history. Uh-oh! Something went wrong, uhoh.\n",
                        "ë³€í™˜: the uk and uk have a long history. uhoh! something went wrong, uhoh.\n"
                    ]
                }
            ],
            "source": [
                "text = \"The United Kingdom and UK have a long history. Uh-oh! Something went wrong, uhoh.\"\n",
                "\n",
                "# 1. ì‚¬ì „ì— ì •ì˜ëœ ê·œì¹™ëŒ€ë¡œ ë°”ê¾¸ê¸° (Dictionary í™œìš©)\n",
                "replace_dict = {\n",
                "    \"United Kingdom\": \"UK\",\n",
                "    \"Uh-oh\": \"uhoh\"\n",
                "}\n",
                "\n",
                "transformed_text = text\n",
                "for key, value in replace_dict.items():\n",
                "    transformed_text = transformed_text.replace(key, value)\n",
                "\n",
                "# 2. ì†Œë¬¸ìë¡œ ì‹¹ í†µì¼í•˜ê¸°\n",
                "final_text = transformed_text.lower()\n",
                "\n",
                "print(\"ì›ë³¸:\", text)\n",
                "print(\"ë³€í™˜:\", final_text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. ë¶ˆìš©ì–´(Stopwords) ì œê±° ğŸš«\n",
                "\n",
                "ìì£¼ ë“±ì¥í•˜ì§€ë§Œ ì‹¤ì œ ì˜ë¯¸ ë¶„ì„ì—ëŠ” ë„ì›€ ì•ˆ ë˜ëŠ” ë‹¨ì–´ë“¤(ì¡°ì‚¬, ê´€ì‚¬ ë“±)ì„ **ë¶ˆìš©ì–´**ë¼ê³  í•´.\n",
                "ì´ê±¸ ì†ì•„ë‚´ì•¼ ì§„ì§œ í•µì‹¬ í‚¤ì›Œë“œê°€ ë³´ì—¬!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì˜ì–´ ë¶ˆìš©ì–´ ê°œìˆ˜: 198\n",
                        "ëª‡ ê°œë§Œ ë³¼ê¹Œ? ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
                        "\n",
                        "ì „: ['Family', 'is', 'not', 'an', 'important', 'thing', '.', 'It', \"'s\", 'everything', '.']\n",
                        "í›„: ['Family', 'important', 'thing', '.', \"'s\", 'everything', '.']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n",
                        "[nltk_data] Downloading package punkt to /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "from nltk.corpus import stopwords\n",
                "from nltk.tokenize import word_tokenize\n",
                "import nltk\n",
                "\n",
                "nltk.download('stopwords')\n",
                "nltk.download('punkt')\n",
                "\n",
                "text = \"Family is not an important thing. It's everything.\"\n",
                "\n",
                "# 1. NLTKê°€ ì œê³µí•˜ëŠ” ì˜ì–´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
                "stop_words_list = stopwords.words('english')\n",
                "print(\"ì˜ì–´ ë¶ˆìš©ì–´ ê°œìˆ˜:\", len(stop_words_list))\n",
                "print(\"ëª‡ ê°œë§Œ ë³¼ê¹Œ?\", stop_words_list[:10])\n",
                "\n",
                "# 2. í† í°í™” ë¨¼ì € ìˆ˜í–‰\n",
                "tokens = word_tokenize(text)\n",
                "\n",
                "# 3. ë¶ˆìš©ì–´ ì œê±° (í•µì‹¬!)\n",
                "# \"í† í°ì´ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ì‚´ë¦¬ê³ , ìˆìœ¼ë©´ ì£½ì—¬ë¼!\"\n",
                "result = [word for word in tokens if word.lower() not in stop_words_list]\n",
                "\n",
                "print(\"\\nì „:\", tokens)\n",
                "print(\"í›„:\", result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ’¡ ê²°ê³¼ ë¶„ì„\n",
                "- `is`, `not`, `an`, `it`, `s` ê°™ì€ ê²ƒë“¤ì´ ì‚¬ë¼ì¡Œì–´.\n",
                "- `Family`, `important`, `thing`, `everything` ê°™ì€ **ì‹¤ì§ˆì ì¸ ì˜ë¯¸**ë¥¼ ê°€ì§„ ë‹¨ì–´ë§Œ ë‚¨ì•˜ì§€?\n",
                "- ì´ë ‡ê²Œ í•˜ë©´ ì»´í“¨í„°ê°€ ì²˜ë¦¬í•´ì•¼ í•  ë°ì´í„° ì–‘ë„ ì¤„ê³ , ì„±ëŠ¥ë„ ì¢‹ì•„ì ¸! ğŸ‘"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. í•œêµ­ì–´ ë¶ˆìš©ì–´ ì œê±° ğŸ‡°ğŸ‡·\n",
                "í•œêµ­ì–´ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ ì œê³µí•˜ëŠ” ë¶ˆìš©ì–´ ì‚¬ì „ì´ ë”±íˆ ì •í•´ì§„ ê²Œ ì—†ì–´ì„œ, ë³´í†µ ê°œë°œìê°€ ì§ì ‘ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ì–´ì„œ ì¨."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from konlpy.tag import Okt\n",
                "\n",
                "okt = Okt()\n",
                "text = \"ê³ ê¸°ë¥¼ ë¨¹ì—ˆì–´. ì–´? ì§„ì§œ ë§›ìˆë„¤. ì™€ ìš°!\"\n",
                "\n",
                "# 1. ë‚˜ë§Œì˜ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
                "stop_words = \"ì–´ ë‚˜ ìš°ë¦¬ ì§„ì§œ ì™€ ìš° íœ´ ì•„ì´êµ¬\"\n",
                "stop_words = stop_words.split(' ')\n",
                "\n",
                "# 2. í˜•íƒœì†Œ ë¶„ì„\n",
                "tokens = okt.morphs(text)\n",
                "\n",
                "# 3. ì œê±° ìˆ˜í–‰\n",
                "result = [word for word in tokens if word not in stop_words]\n",
                "\n",
                "print(\"ì „:\", tokens)\n",
                "print(\"í›„:\", result)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q. 'Garbage In, Garbage Out'ì€ NLPì—ì„œ ì–´ë–¤ ì˜ë¯¸ì¼ê¹Œ?**\n",
                "1. ì“°ë ˆê¸°í†µì„ ë°ì´í„°ë¡œ ì±„ìš°ë¼ëŠ” ëœ»\n",
                "2. ì •ì œë˜ì§€ ì•Šì€(ë”ëŸ¬ìš´) ë°ì´í„°ë¥¼ ë„£ìœ¼ë©´ ê²°ê³¼ë„ ì—‰ë§ìœ¼ë¡œ ë‚˜ì˜¨ë‹¤ëŠ” ëœ»\n",
                "3. ì»´í“¨í„°ëŠ” ì¬í™œìš©ì„ ì˜í•œë‹¤ëŠ” ëœ»\n",
                "\n",
                "<details>\n",
                "<summary>ì •ë‹µ í™•ì¸</summary>\n",
                "\n",
                "**2ë²ˆ** (ê·¸ë˜ì„œ ì •ì œ/ì •ê·œí™”ê°€ ì¤‘ìš”í•œ ê±°ì•¼!)\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
