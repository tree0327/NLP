{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5874ca48",
            "metadata": {},
            "source": [
                "# ğŸ§± 1. í† í°í™” (Tokenization): ë ˆê³  ë¸”ë¡ ë¶„í•´í•˜ê¸°\n",
                "\n",
                "> **\"ë¬¸ì¥ì„ ì¡°ë¦½í•˜ê¸° ì „, ê°€ì¥ ì‘ì€ ë¶€í’ˆ(ë¸”ë¡)ìœ¼ë¡œ ìª¼ê°œì!\"**\n",
                "\n",
                "NLP(ìì—°ì–´ ì²˜ë¦¬)ì˜ ê°€ì¥ ì²« ë²ˆì§¸ ë‹¨ê³„ëŠ” **í† í°í™”**ì•¼.\n",
                "ê±°ëŒ€í•œ ë ˆê³  ì„±(ë¬¸ì¥)ì„ ë¶„ì„í•˜ë ¤ë©´, ì¼ë‹¨ í•˜ë‚˜í•˜ë‚˜ì˜ ë¸”ë¡(ë‹¨ì–´)ìœ¼ë¡œ ë¶„í•´í•´ì•¼ê² ì§€?\n",
                "\n",
                "### ğŸ¯ ì˜¤ëŠ˜ì˜ í•™ìŠµ ëª©í‘œ\n",
                "1. ë¬¸ì¥ì„ ë¬¸ì¥ë³„ë¡œ ë‚˜ëˆ„ê¸° (Sentence Tokenization)\n",
                "2. ë¬¸ì¥ì„ ë‹¨ì–´ë³„ë¡œ ë‚˜ëˆ„ê¸° (Word Tokenization)\n",
                "3. í•œêµ­ì–´ëŠ” ì–´ë–»ê²Œ í• ê¹Œ? (KoNLPy)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7e9bc7ee",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "81d386f6",
            "metadata": {},
            "source": [
                "## 1. ë¬¸ì¥ í† í°í™” (Sentence Tokenization) ğŸ“„ -> âœ‚ï¸ -> ğŸ“„ğŸ“„\n",
                "\n",
                "ë¬¸ë‹¨ì´ ì£¼ì–´ì¡Œì„ ë•Œ, **\"ì–´ë””ê¹Œì§€ê°€ í•œ ë¬¸ì¥ì´ì§€?\"** ë¥¼ ìë¥´ëŠ” ì‘ì—…ì´ì•¼.\n",
                "ë‹¨ìˆœíˆ ë§ˆì¹¨í‘œ(`.`)ë¡œ ìë¥´ë©´ ì•ˆ ë¼. (ì˜ˆ: `Mr. Kim`ì€ ë¬¸ì¥ì´ ëë‚œ ê²Œ ì•„ë‹ˆë‹ˆê¹Œ!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "04e406ef",
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk.tokenize import sent_tokenize\n",
                "import nltk\n",
                "\n",
                "# í•„ìš”í•œ ë°ì´í„° ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)\n",
                "nltk.download('punkt')\n",
                "\n",
                "text = \"His barber kept his word. But keeping such a huge secret to himself was driving him crazy. Finally, the barber went up a mountain and almost to the edge of a cliff. He dug a hole in the midst of some reeds. He looked about, to make sure no one was near.\"\n",
                "\n",
                "# ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°\n",
                "sentences = sent_tokenize(text)\n",
                "\n",
                "print(f\"ì´ ë¬¸ì¥ ê°œìˆ˜: {len(sentences)}ê°œ\")\n",
                "print(\"====================\")\n",
                "for i, sent in enumerate(sentences):\n",
                "    print(f\"ë¬¸ì¥ {i+1}: {sent}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e5dc42ec",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c2b6186a",
            "metadata": {},
            "source": [
                "## 2. ë‹¨ì–´ í† í°í™” (Word Tokenization) ğŸ§±\n",
                "\n",
                "ì´ì œ ë¬¸ì¥ì„ **ë‹¨ì–´(Word)** ë‹¨ìœ„ë¡œ ë” ì˜ê²Œ ìª¼ê°œë³´ì.\n",
                "ì˜ì–´ëŠ” ë„ì–´ì“°ê¸° ê¸°ì¤€ìœ¼ë¡œ ìë¥´ë©´ ì–¼ì¶” ë§ì§€ë§Œ, `Do n't` ì²˜ëŸ¼ ì¤„ì„ë§ ì²˜ë¦¬ê°€ ì¤‘ìš”í•´."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d39bb6b0",
            "metadata": {},
            "outputs": [],
            "source": [
                "from nltk.tokenize import word_tokenize\n",
                "from nltk.tokenize import WordPunctTokenizer\n",
                "\n",
                "text = \"Don't be fooled by the dark sounding name, Mr. Jone's Orphanage is as cheery as cheery goes for a pastry shop.\"\n",
                "\n",
                "# ë°©ë²• 1: word_tokenize (ê°€ì¥ í‘œì¤€ì ì¸ ë°©ë²•)\n",
                "print(\"Standard:\", word_tokenize(text))\n",
                "\n",
                "# ë°©ë²• 2: WordPunctTokenizer (êµ¬ë‘ì ì„ ë³„ë„ë¡œ ë¶„ë¦¬)\n",
                "print(\"WordPunct:\", WordPunctTokenizer().tokenize(text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1831f408",
            "metadata": {},
            "source": [
                "### ğŸ’¡ ê²°ê³¼ ë¹„êµ\n",
                "- **Standard**: `Do`, `n't` ì²˜ëŸ¼ ì•„í¬ìŠ¤íŠ¸ë¡œí”¼(')ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ì²˜ë¦¬í•´.\n",
                "- **WordPunct**: `Don`, `'`, `t` ì²˜ëŸ¼ ë¬´ì‹í•˜ê²Œ íŠ¹ìˆ˜ë¬¸ìë©´ ë‹¤ ì˜ë¼ë²„ë ¤.\n",
                "-> ìƒí™©ì— ë§ëŠ” ë„êµ¬ë¥¼ ê³¨ë¼ ì“°ëŠ” ê²Œ ì‹¤ë ¥ì´ì•¼! ğŸ˜"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "33263d39",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "352c67a0",
            "metadata": {},
            "source": [
                "## 3. í•œêµ­ì–´ í† í°í™” (KoNLPy) ğŸ‡°ğŸ‡·\n",
                "\n",
                "ì˜ì–´ëŠ” ë„ì–´ì“°ê¸°ë§Œ í•´ë„ ë°˜ì€ ê°€ì§€ë§Œ, í•œêµ­ì–´ëŠ” **ì¡°ì‚¬(ì€, ëŠ”, ì´, ê°€)** ë•Œë¬¸ì— ë„ì–´ì“°ê¸°ë§Œìœ¼ë¡  ì•ˆ ë¼.\n",
                "- ì˜ì–´: `I loves you` (I / loves / you)\n",
                "- í•œêµ­ì–´: `ë‚˜ëŠ” ë„ˆë¥¼ ì‚¬ë‘í•´` (ë‚˜ / ëŠ” / ë„ˆ / ë¥¼ / ì‚¬ë‘í•´)\n",
                "\n",
                "ê·¸ë˜ì„œ **í˜•íƒœì†Œ ë¶„ì„ê¸°**ê°€ í•„ìš”í•´!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a947bc0c",
            "metadata": {},
            "outputs": [],
            "source": [
                "from konlpy.tag import Okt\n",
                "from konlpy.tag import Kkma\n",
                "\n",
                "text = \"ì—´ì‹¬íˆ ì½”ë”©í•œ ë‹¹ì‹ , ë– ë‚˜ë¼!\"\n",
                "\n",
                "# 1. Okt (Open Korean Text) - íŠ¸ìœ„í„° ë¶„ì„ê¸° (ë¹ ë¥´ê³  ì“°ê¸° í¸í•¨)\n",
                "okt = Okt()\n",
                "print(\"Okt í˜•íƒœì†Œ:\", okt.morphs(text)) \n",
                "print(\"Okt ëª…ì‚¬ë§Œ:\", okt.nouns(text))\n",
                "\n",
                "# 2. Kkma (ê¼¬ê¼¬ë§ˆ) - ì„œìš¸ëŒ€ì—ì„œ ë§Œë“¦ (ì •ë°€í•˜ì§€ë§Œ ì¡°ê¸ˆ ëŠë¦¼)\n",
                "kkma = Kkma()\n",
                "print(\"Kkma í˜•íƒœì†Œ:\", kkma.morphs(text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "78191d7b",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q. í•œêµ­ì–´ ìì—°ì–´ ì²˜ë¦¬ê°€ ì˜ì–´ë³´ë‹¤ ì–´ë ¤ìš´ ëŒ€í‘œì ì¸ ì´ìœ ëŠ”?**\n",
                "1. ë‹¨ì–´ê°€ ë„ˆë¬´ ë§ì•„ì„œ\n",
                "2. ë„ì–´ì“°ê¸° ë‹¨ìœ„ê°€ ë‹¨ì–´ì™€ ì¼ì¹˜í•˜ì§€ ì•Šê³ , 'ì¡°ì‚¬'ê°€ ë¶™ì–´ ìˆì–´ì„œ\n",
                "3. ì»´í“¨í„°ê°€ í•œê¸€ í°íŠ¸ë¥¼ ì‹«ì–´í•´ì„œ\n",
                "\n",
                "<details>\n",
                "<summary>ì •ë‹µ í™•ì¸</summary>\n",
                "\n",
                "**2ë²ˆ** (ê·¸ë˜ì„œ í˜•íƒœì†Œ ë¶„ì„ê¸°ê°€ ê¼­ í•„ìš”í•´!)\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "python3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
