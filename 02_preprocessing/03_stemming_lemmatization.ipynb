{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸŒ± 3. ì–´ê°„ ì¶”ì¶œ(Stemming) & í‘œì œì–´ ì¶”ì¶œ(Lemmatization): ë¿Œë¦¬ ì°¾ê¸°\n",
                "\n",
                "> **\"ë³€ì¥í•´ë„ ì†Œìš©ì—†ë‹¤! ë„ˆì˜ ë³¸ëª¨ìŠµ(ì›í˜•)ì„ ì°¾ì•„ì£¼ë§ˆ!\"**\n",
                "\n",
                "- **am, are, is** -> ì‚¬ì‹¤ ë‹¤ **be** ë™ì‚¬ì–ì•„?\n",
                "- **running, runs, ran** -> ì‚¬ì‹¤ ë‹¤ **run** ì´ì–ì•„?\n",
                "\n",
                "ì»´í“¨í„°ì—ê²Œ \"ì´ê±° ë‹¤ ê°™ì€ ë‹¨ì–´ë‹ˆê¹Œ ë”°ë¡œ ê³µë¶€í•˜ì§€ ë§ê³  í•œ ë²ˆì— í‰ì³!\" ë¼ê³  ì•Œë ¤ì£¼ëŠ” ê¸°ìˆ ì´ì•¼.\n",
                "ë‹¨ì–´ì˜ ê°œìˆ˜ë¥¼ í™• ì¤„ì—¬ì¤˜ì„œ(í¬ì†Œì„± ë¬¸ì œ í•´ê²°) í•™ìŠµ íš¨ìœ¨ì„ ë†’ì—¬ì¤˜."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ì–´ê°„ ì¶”ì¶œ (Stemming) ğŸª“\n",
                "\n",
                "ì´ê±´ ì¢€ **ë¬´ì‹í•œ ë°©ë²•**ì´ì•¼. ë‹¨ì–´ì˜ ëë¶€ë¶„(ì ‘ë¯¸ì‚¬)ì„ ê·¸ëƒ¥ ì¹¼ë¡œ ëŒ•ê°• ì˜ë¼ë²„ë ¤.\n",
                "ê·œì¹™ ê¸°ë°˜ì´ë¼ì„œ ì‚¬ì „ì— ì—†ëŠ” ì´ìƒí•œ ë‹¨ì–´ê°€ íŠ€ì–´ë‚˜ì˜¬ ìˆ˜ë„ ìˆì–´.\n",
                "\n",
                "- ëŒ€í‘œ ì„ ìˆ˜: **Porter Stemmer** (í¬í„° ìŠ¤í…Œë¨¸)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì›ë³¸: ['The', 'gamers', 'are', 'gaming', 'in', 'the', 'game', 'room', 'because', 'they', 'love', 'games', '.']\n",
                        "ê²°ê³¼: ['the', 'gamer', 'are', 'game', 'in', 'the', 'game', 'room', 'becaus', 'they', 'love', 'game', '.']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.stem import PorterStemmer\n",
                "from nltk.tokenize import word_tokenize\n",
                "\n",
                "stemmer = PorterStemmer()\n",
                "\n",
                "text = \"The gamers are gaming in the game room because they love games.\"\n",
                "tokens = word_tokenize(text)\n",
                "\n",
                "# ê°ê°ì˜ í† í°ì„ ìŠ¤í…Œë¨¸ì— ë„£ê³  ëŒë¦¬ê¸°\n",
                "results = [stemmer.stem(word) for word in tokens]\n",
                "\n",
                "print(\"ì›ë³¸:\", tokens)\n",
                "print(\"ê²°ê³¼:\", results)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ’¡ ê²°ê³¼ ë¶„ì„\n",
                "- `gamers` -> `gamer` (ì˜¤ ì¢‹ë„¤!)\n",
                "- `gaming` -> `game` (ì´ê²ƒë„ êµ¿!)\n",
                "- `games` -> `game` (êµ¿!)\n",
                "- ê·¼ë° ë§Œì•½ `organization`ì„ ë„£ìœ¼ë©´ `organ` (ì¥ê¸°?)ì´ ë˜ì–´ë²„ë¦´ ìˆ˜ë„ ìˆì–´. ğŸ˜… (ë‹¨ìˆœ ê·œì¹™ì˜ í•œê³„)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. í‘œì œì–´ ì¶”ì¶œ (Lemmatization) ğŸ“–\n",
                "\n",
                "ì´ê±´ ì¢€ ë” **ë˜‘ë˜‘í•œ ë°©ë²•**ì´ì•¼.\n",
                "ê·¸ëƒ¥ ìë¥´ëŠ” ê²Œ ì•„ë‹ˆë¼, **ì‚¬ì „(WordNet)**ì„ ë’¤ì ¸ì„œ ì§„ì§œ ê¸°ë³¸í˜•(í‘œì œì–´)ì„ ì°¾ì•„ë‚´.\n",
                "\n",
                "- ëŒ€í‘œ ì„ ìˆ˜: **WordNet Lemmatizer**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package wordnet to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package wordnet is already up-to-date!\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "í‘œì œì–´ ì¶”ì¶œ ì „: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
                        "í‘œì œì–´ ì¶”ì¶œ í›„: ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
                    ]
                }
            ],
            "source": [
                "from nltk.stem import WordNetLemmatizer\n",
                "import nltk\n",
                "\n",
                "nltk.download('wordnet')\n",
                "\n",
                "lemmatizer = WordNetLemmatizer()\n",
                "\n",
                "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
                "\n",
                "print(\"í‘œì œì–´ ì¶”ì¶œ ì „:\", words)\n",
                "print(\"í‘œì œì–´ ì¶”ì¶œ í›„:\", [lemmatizer.lemmatize(word) for word in words])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ğŸ¤” ê²°ê³¼ê°€ ì¢€ ì´ìƒí•œë°?\n",
                "`has` -> `ha`, `dies` -> `dy` ì²˜ëŸ¼ ë³€í–ˆì–´. ì™œ ê·¸ëŸ´ê¹Œ?\n",
                "LemmatizerëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ë‹¨ì–´ê°€ **'ëª…ì‚¬(Noun)'ë¼ê³  ê°€ì •**í•˜ê³  ì°¾ì•„ì„œ ê·¸ë˜.\n",
                "\n",
                "ê·¸ë˜ì„œ **\"ì•¼, ì´ê±° ë™ì‚¬(Verb)ì•¼!\"** ë¼ê³  í’ˆì‚¬(POS)ë¥¼ ì•Œë ¤ì¤˜ì•¼ ì œëŒ€ë¡œ ì‘ë™í•´."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# pos='v' (verb, ë™ì‚¬) ì˜µì…˜ì„ ì¤˜ë³´ì!\n",
                "print(\"dies ->\", lemmatizer.lemmatize('dies', pos='v'))\n",
                "print(\"watched ->\", lemmatizer.lemmatize('watched', pos='v'))\n",
                "print(\"has ->\", lemmatizer.lemmatize('has', pos='v'))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ì´ì œ ì œëŒ€ë¡œ `die`, `watch`, `have`ê°€ ë‚˜ì™”ì§€? ğŸ‘"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q. 'ì–´ê°„ ì¶”ì¶œ(Stemming)'ê³¼ 'í‘œì œì–´ ì¶”ì¶œ(Lemmatization)'ì˜ ê°€ì¥ í° ì°¨ì´ëŠ”?**\n",
                "1. Stemmingì€ ê·œì¹™ ê¸°ë°˜(ë‹¨ìˆœ ì ˆë‹¨), Lemmatizationì€ ì‚¬ì „ ê¸°ë°˜(ì˜ë¯¸ íŒŒì•…)\n",
                "2. Stemmingì€ í•œêµ­ì–´ìš©, Lemmatizationì€ ì˜ì–´ìš©\n",
                "3. Stemmingì€ ëˆì´ ë“¤ê³ , Lemmatizationì€ ê³µì§œë‹¤\n",
                "\n",
                "<details>\n",
                "<summary>ì •ë‹µ í™•ì¸</summary>\n",
                "\n",
                "**1ë²ˆ** (Stemmingì€ ì‹¹ë‘‘! Lemmatizationì€ ë˜‘ë˜‘!)\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
