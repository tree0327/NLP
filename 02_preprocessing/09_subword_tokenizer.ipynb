{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# âš›ï¸ 9. ì„œë¸Œì›Œë“œ í† í°í™” (Subword Tokenization): ë” ì˜ê²Œ ìª¼ê°œê¸°\n",
                "\n",
                "> **\"'Apple-pie'ë¥¼ ëª¨ë¥¸ë‹¤ê³ ? 'Apple'ì´ë‘ 'pie'ëŠ” ì•Œì–ì•„!\"**\n",
                "\n",
                "ê¸°ì¡´ ë‹¨ì–´ ì‚¬ì „(Vocabulary)ì— ì—†ëŠ” ë‹¨ì–´ê°€ ë‚˜ì˜¤ë©´ ì»´í“¨í„°ëŠ” ë‹¹í™©í•´.\n",
                "ì´ê±¸ **OOV (Out-Of-Vocabulary) ë¬¸ì œ**ë¼ê³  í•´.\n",
                "\n",
                "ì´ê±¸ í•´ê²°í•˜ê¸° ìœ„í•´, ë‹¨ì–´ë¥¼ ë” ì‘ì€ ë‹¨ìœ„(Subword)ë¡œ ìª¼ê°œì„œ ì¡°ë¦½í•˜ëŠ” ë°©ì‹ì´ì•¼.\n",
                "ìš”ì¦˜ ë‚˜ì˜¤ëŠ” ìµœì‹  AI ëª¨ë¸(BERT, GPT ë“±)ì€ ë‹¤ ì´ê±¸ ì¨!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. BPE (Byte Pair Encoding) ê°œë… ì´í•´ ğŸ§ \n",
                "\n",
                "ê°€ì¥ ë§ì´ ì“°ì´ëŠ” ê¸€ì ìŒì„ ì°¾ì•„ì„œ í•˜ë‚˜ë¡œ í•©ì¹˜ëŠ” ë°©ì‹ì´ì•¼.\n",
                "\n",
                "1. `l o w` (5ë²ˆ), `l o w e r` (2ë²ˆ), `n e w e s t` (6ë²ˆ), `w i d e s t` (3ë²ˆ)\n",
                "2. `es`ì™€ `t`ê°€ ìì£¼ ë¶™ì–´ ë‚˜ì˜¤ë„¤? -> `est`ë¡œ í•©ì²´!\n",
                "3. `low`ê°€ ìì£¼ ë‚˜ì˜¤ë„¤? -> `low`ë¡œ í•©ì²´!\n",
                "4. ê²°ê³¼: `low`, `er`, `new`, `est`, `wid`... ì´ëŸ° ì¡°ê°ë“¤ì´ ì‚¬ì „ì— ë“±ë¡ë¨.\n",
                "\n",
                "-> ë‚˜ì¤‘ì— `lowest`ê°€ ë‚˜ì˜¤ë©´? `low` + `est` ë‘ ì¡°ê°ì„ ì¡°ë¦½í•´ì„œ ì¸ì‹ ê°€ëŠ¥! ğŸ‰"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. HuggingFace Tokenizers ì‹¤ìŠµ ğŸ¤—\n",
                "BERT ëª¨ë¸ì´ ì“°ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ êµ¬ê²½í•´ë³´ì."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "42860042",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import BertTokenizer\n",
                "\n",
                "# BERTì˜ ê¸°ë³¸ í† í¬ë‚˜ì´ì € ë¶ˆëŸ¬ì˜¤ê¸°\n",
                "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "\n",
                "text = \"I have a new GPU!\"\n",
                "\n",
                "# í† í°í™” ê²°ê³¼\n",
                "print(tokenizer.tokenize(text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c5badf95",
            "metadata": {},
            "source": [
                "### 2-1. BERTì˜ í† í¬ë‚˜ì´ì € (WordPiece) ğŸ¤–\n",
                "\n",
                "êµ¬ê¸€ì˜ BERTëŠ” **\"ëª¨ë¥´ëŠ” ë‹¨ì–´ë„ í¬ê¸°í•˜ì§€ ì•Šê³  ìª¼ê°œì„œ ì´í•´í•œë‹¤\"**ëŠ” ì² í•™ì„ ê°€ì§€ê³  ìˆì–´.\n",
                "ì´ê±¸ ì‹¤ìŠµí•´ë³´ì!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "991fc808",
            "metadata": {},
            "outputs": [],
            "source": [
                "from transformers import BertTokenizer\n",
                "\n",
                "# 1. 'bert-base-uncased'ë€?\n",
                "# - bert-base: êµ¬ê¸€ì´ ì˜ì–´ ê³µë¶€ë¥¼ ì‹œí‚¨ ê¸°ë³¸ ëª¨ë¸\n",
                "# - uncased: ëª¨ë“  ëŒ€ë¬¸ìë¥¼ ì†Œë¬¸ìë¡œ ë°”ê¿”ì„œ í•™ìŠµí–ˆë‹¤ëŠ” ëœ» ('English' -> 'english')\n",
                "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
                "\n",
                "text = \"I have a new GPU!\"\n",
                "\n",
                "# 2. í† í°í™” ê²°ê³¼ í™•ì¸\n",
                "print(\"ì›ë³¸:\", text)\n",
                "print(\"í† í°í™”:\", tokenizer.tokenize(text))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b75f2690",
            "metadata": {},
            "source": [
                "### ğŸ’¡ ê²°ê³¼ ë¶„ì„: ì™œ 'GPU'ê°€ `['gp', '##u']`ê°€ ëì„ê¹Œ? ğŸ”ª\n",
                "\n",
                "ê²°ê³¼: `['i', 'have', 'a', 'new', 'gp', '##u', '!']`\n",
                "\n",
                "1. **`GPU`**ë¼ëŠ” ë‹¨ì–´ëŠ” BERTì˜ ë‹¨ì–´ì¥(ì˜›ë‚  ë²„ì „)ì— ì—†ì—ˆì–´.\n",
                "2. ê¸°ì¡´ ê°™ìœ¼ë©´ `OOV`(ëª¨ë¦„) ì²˜ë¦¬í–ˆê² ì§€ë§Œ, BERTëŠ” í¬ê¸°í•˜ì§€ ì•Šì•„.\n",
                "3. \"ì•„ëŠ” ê±°ë¼ë„ ì°¾ì!\" -> `gp`ëŠ” ì•„ëŠ” ë‹¨ì–´ë„¤? (General Practitioner ë“±)\n",
                "4. \"ë‚˜ë¨¸ì§€ `u`ëŠ” í˜¼ì ë‚¨ì•˜ë„¤?\" -> ì•ì— **`##`**ì„ ë¶™ì—¬ì„œ **\"ì–˜ëŠ” ì›ë˜ ì• ë‹¨ì–´ë‘ ë¶™ì–´ìˆë˜ ì• ì˜ˆìš”\"**ë¼ê³  í‘œì‹œí•¨.\n",
                "\n",
                "**ê²°ë¡ **: `GPU` = `gp` + `##u` (ì´ë ‡ê²Œ ìª¼ê°œì„œë¼ë„ ì˜ë¯¸ë¥¼ ë³´ì¡´í•˜ë ¤ê³  ë…¸ë ¥í•˜ëŠ” ê±°ì•¼!)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "07caad60",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì›ë³¸: unaffable\n",
                        "í† í°í™”: ['una', '##ffa', '##ble']\n"
                    ]
                }
            ],
            "source": [
                "# ë” ì–´ë ¤ìš´ ë‹¨ì–´ í…ŒìŠ¤íŠ¸ (OOV)\n",
                "# 'unaffable' (ë¶™ì„ì„± ì—†ëŠ”)ì€ ì‚¬ì „ì— ì—†ì„ í™•ë¥ ì´ ë†’ì•„.\n",
                "text2 = \"unaffable\"\n",
                "\n",
                "print(\"ì›ë³¸:\", text2)\n",
                "print(\"í† í°í™”:\", tokenizer.tokenize(text2))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed6f10d3",
            "metadata": {},
            "source": [
                "### í™•ì¸ì‚¬ì‚´ âœ¨\n",
                "`['un', '##aff', '##able']`ë¡œ ë‚˜ì™”ì§€?\n",
                "BERTëŠ” `unaffable`ì„ í†µì§¸ë¡œëŠ” ëª¨ë¥´ì§€ë§Œ, `un`(ë°˜ëŒ€), `aff`(ì–´ê·¼), `able`(ê°€ëŠ¥)ì´ë¼ëŠ” **ì˜ë¯¸ ë‹¨ìœ„ ì¡°ê°**ë“¤ì€ ì•Œê³  ìˆì–´.\n",
                "ê·¸ë˜ì„œ ì´ê±¸ ì¡°ë¦½í•´ì„œ \"ì•„, ë­”ê°€ 'ê°€ëŠ¥í•˜ì§€ ì•Šì€' ëœ»ì´ê² êµ¬ë‚˜\"ë¼ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆëŠ” ê±°ì§€. ë˜‘ë˜‘í•˜ì§€? ğŸ§ "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ“ ë§ˆë¬´ë¦¬ í€´ì¦ˆ\n",
                "\n",
                "**Q. OOV(ë¯¸ë“±ë¡ ë‹¨ì–´) ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ë‹¨ì–´ë¥¼ ë” ì‘ì€ ë‹¨ìœ„ë¡œ ìª¼ê°œëŠ” ë°©ì‹ì€?**\n",
                "1. ë¬¸ì¥ í† í°í™”\n",
                "2. ì„œë¸Œì›Œë“œ(Subword) í† í°í™”\n",
                "3. ì›-í•« ì¸ì½”ë”©\n",
                "\n",
                "<details>\n",
                "<summary>ì •ë‹µ í™•ì¸</summary>\n",
                "\n",
                "**2ë²ˆ**\n",
                "\n",
                "</details>"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
