{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ğŸ‘¨â€ğŸ³ NLP ìš”ë¦¬ êµì‹¤: ì‹¤ì „ ìš”ë¦¬ íƒ€ì„!\n",
                "\n",
                "ì§€ê¸ˆê¹Œì§€ ì¬ë£Œ ì†ì§ˆ(í† í°í™”, ì •ì œ), ë„êµ¬ ì‚¬ìš©ë²•(ì •ê·œí‘œí˜„ì‹) ë“±ì„ ë‹¤ ë°°ì› ì–´.\n",
                "ì´ì œ ë°°ìš´ ê±¸ ì´ë™ì›í•´ì„œ **\"ê°€ì¥ ë§›ìˆëŠ” ë‹¨ì–´ ìš”ë¦¬\"**ë¥¼ ë§Œë“¤ì–´ë³´ì.\n",
                "\n",
                "**ì˜¤ëŠ˜ì˜ ë¯¸ì…˜:**\n",
                "1. ë”ëŸ¬ìš´ í…ìŠ¤íŠ¸ë¥¼ ì²­ì†Œí•˜ê³  (ì •ì œ)\n",
                "2. ë¨¹ê¸° ì¢‹ê²Œ ì°ì–´ì„œ (í† í°í™”)\n",
                "3. ì–´ë–¤ ì¬ë£Œê°€ ì œì¼ ë§ì´ ë“¤ì–´ê°”ë‚˜ í™•ì¸í•´ë¼! (ë¹ˆë„ ë¶„ì„)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. ì¬ë£Œ ì¤€ë¹„ (Raw Data) ğŸ¥©\n",
                "ì¸í„°ë„·ì—ì„œ ê¸ì–´ì˜¨(Crawling) ì•„ì£¼ ì§€ì €ë¶„í•œ ëŒ“ê¸€ ë°ì´í„°ê°€ ìˆë‹¤ê³  ì¹˜ì."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì›ë³¸: \n",
                        "Goood movie!!! I loved it. â¤ï¸ \n",
                        "The acting was terrible... I hated it. ğŸ˜¡\n",
                        "Best movie ever! EVER! 10/10 points.\n",
                        "Don't watch this. Waste of time.\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "raw_text = \"\"\"\n",
                "Goood movie!!! I loved it. â¤ï¸ \n",
                "The acting was terrible... I hated it. ğŸ˜¡\n",
                "Best movie ever! EVER! 10/10 points.\n",
                "Don't watch this. Waste of time.\n",
                "\"\"\"\n",
                "\n",
                "print(\"ì›ë³¸:\", raw_text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 1ì°¨ ì„¸ì²™: ì •ì œ & ì •ê·œí™” ğŸ§¼\n",
                "ëŒ€ì†Œë¬¸ìë¥¼ í†µì¼í•˜ê³ , íŠ¹ìˆ˜ë¬¸ìë‚˜ ì´ëª¨ì§€ë¥¼ ì œê±°í•´ë³´ì."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ì„¸ì²™ í›„: goood movie i loved it  the acting was terrible i hated it best movie ever ever 1010 pointsdont watch this waste of time\n"
                    ]
                }
            ],
            "source": [
                "import re\n",
                "\n",
                "# 1. ì†Œë¬¸ìë¡œ ë³€í™˜\n",
                "text = raw_text.lower()\n",
                "\n",
                "# 2. ì˜ì–´ë‚˜ ìˆ«ì, ê³µë°±ì´ ì•„ë‹ˆë©´ ë‹¤ ì—†ì• ì! (íŠ¹ìˆ˜ë¬¸ì, ì´ëª¨ì§€ ì œê±°)\n",
                "text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
                "\n",
                "print(\"ì„¸ì²™ í›„:\", text)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. ì¬ë£Œ ì°ê¸°: í† í°í™” ğŸ”ª\n",
                "ë‹¨ì–´ ë‹¨ìœ„ë¡œ ë‹¤ ì˜ë¼ë²„ë ¤!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "í† í°ë“¤: ['goood', 'movie', 'i', 'loved', 'it', 'the', 'acting', 'was', 'terrible', 'i', 'hated', 'it', 'best', 'movie', 'ever', 'ever', '1010', 'pointsdont', 'watch', 'this', 'waste', 'of', 'time']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package punkt to /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package punkt is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "from nltk.tokenize import word_tokenize\n",
                "import nltk\n",
                "nltk.download('punkt')\n",
                "\n",
                "tokens = word_tokenize(text)\n",
                "print(\"í† í°ë“¤:\", tokens)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. ë¶ˆìˆœë¬¼ ì œê±°: ë¶ˆìš©ì–´ ì²˜ë¦¬ ğŸ—‘ï¸\n",
                "`the`, `it`, `of` ê°™ì€ ì¡°ë¯¸ë£ŒëŠ” ë¹¼ê³  ë³¸ì¬ë£Œë§Œ ë‚¨ê²¨."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ìµœì¢… ì¬ë£Œ: ['goood', 'movie', 'loved', 'acting', 'terrible', 'hated', 'best', 'movie', 'ever', 'ever', '1010', 'pointsdont', 'watch', 'waste', 'time']\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "[nltk_data] Downloading package stopwords to\n",
                        "[nltk_data]     /Users/gimdabin/nltk_data...\n",
                        "[nltk_data]   Package stopwords is already up-to-date!\n"
                    ]
                }
            ],
            "source": [
                "from nltk.corpus import stopwords\n",
                "nltk.download('stopwords')\n",
                "\n",
                "stop_words = set(stopwords.words('english'))\n",
                "\n",
                "# ë¦¬ìŠ¤íŠ¸ ì»´í”„ë¦¬í—¨ì…˜(í•„ìˆ˜ ìŠ¤í‚¬!)ìœ¼ë¡œ í•œ ì¤„ì— ì²˜ë¦¬\n",
                "clean_tokens = [t for t in tokens if t not in stop_words]\n",
                "\n",
                "print(\"ìµœì¢… ì¬ë£Œ:\", clean_tokens)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. ë§› í‰ê°€: ë¹ˆë„ ë¶„ì„ ğŸ“Š\n",
                "ì–´ë–¤ ë‹¨ì–´ê°€ ê°€ì¥ ë§ì´ ì–¸ê¸‰ëì„ê¹Œ?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‹¨ì–´ Top 3: [('movie', 2), ('ever', 2), ('goood', 1)]\n"
                    ]
                }
            ],
            "source": [
                "from collections import Counter\n",
                "\n",
                "count = Counter(clean_tokens)\n",
                "print(\"ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ë‹¨ì–´ Top 3:\", count.most_common(3))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## ğŸ‰ ìš”ë¦¬ ì™„ì„±!\n",
                "ì¶•í•˜í•´! ë„ˆëŠ” ì´ì œ ì§€ì €ë¶„í•œ í…ìŠ¤íŠ¸ë¥¼ ë°›ì•„ì„œ ê¹”ë”í•˜ê²Œ ë¶„ì„í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥ì„ ì–»ì—ˆì–´.\n",
                "ì´ì œ ì–´ë–¤ ë°ì´í„°ê°€ ì™€ë„ ë‘ë µì§€ ì•Šê² ì§€? ğŸ˜"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
