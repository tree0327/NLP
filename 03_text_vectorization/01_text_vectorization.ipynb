{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 🔢 1. 텍스트 벡터화 (Text Vectorization): 글자를 숫자로!\n",
                "\n",
                "> **\"컴퓨터는 '사과'를 모른다. 하지만 '[0.1, 0.5]'는 아주 잘 안다!\"**\n",
                "\n",
                "사람은 문자를 읽지만, 컴퓨터(AI)는 100% **숫자 계산**만 할 수 있어.\n",
                "그래서 **텍스트(Text)**를 **숫자 벡터(Vector)**로 바꿔주는 작업을 **'벡터화(Vectorization)'**라고 해.\n",
                "\n",
                "크게 두 가지 유파(방법론)가 있어. 이 두 가지만 이해하면 끝나!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. 희소 표현 (Sparse Representation): \"광활한 호텔\" 🏨\n",
                "\n",
                "단어 하나를 표현하기 위해 **엄청나게 긴 0의 행렬**을 만드는 방식이야.\n",
                "\n",
                "*   **방식**: 사과(1번), 바나나(2번)... 10만 개의 단어가 있다면, **10만 칸짜리 방**을 만들고 해당 단어 칸에만 `1`을 표시해.\n",
                "*   **비유**: \"사과 손님 오셨습니까? 1호실 들어가세요. 나머지 99,999개 방은 다 비워둡니다.\"\n",
                "*   **특징**: \n",
                "    *   직관적이다. (단어 유무 확인 쉬움)\n",
                "    *   **공간 낭비가 심하다.** (대부분이 0)\n",
                "    *   **단어의 의미를 모른다.** (사과와 바나나가 비슷한 과일인지 전혀 모름. 그냥 1번 방, 2번 방일 뿐.)\n",
                "*   **종류**: One-Hot Encoding, Bag of Words(BoW), TF-IDF"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. 밀집 표현 (Dense Representation): \"정밀한 좌표\" 🗺️\n",
                "\n",
                "단어를 **압축된 실수(소수점) 좌표**로 표현하는 방식이야.\n",
                "\n",
                "*   **방식**: 10만 개의 방을 만드는 게 아니라, **단 100개의 방(차원)**에 단어의 **성격(의미)**을 숫자로 채워 넣어.\n",
                "*   **비유**: \"사과는 (단맛: 0.9, 빨강: 0.8, 크기: 0.2) 위치에 있으세요.\"\n",
                "*   **특징**:\n",
                "    *   **공간 효율적이다.** (0이 거의 없음)\n",
                "    *   **의미를 파악한다!** (사과와 바나나는 '과일'이라는 성격 수치가 비슷하게 나옴)\n",
                "*   **종류**: **Word Embedding** (Word2Vec, GloVe, FastText), BERT Embedding"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 🆚 한눈에 비교 (표)\n",
                "\n",
                "| 구분 | 희소 표현 (Sparse) | 밀집 표현 (Dense) |\n",
                "| :--- | :--- | :--- |\n",
                "| **다른 이름** | Local Representation | Distributed Representation |\n",
                "| **비유** | **스위치 켜기** (ON/OFF) 💡 | **지도 좌표 찍기** (GPS) 📍 |\n",
                "| **값의 형태** | `[0, 0, 1, 0, ...]` (0과 1) | `[0.2, -1.5, 0.7]` (실수) |\n",
                "| **장점** | 만들기 쉽고 직관적임 | **의미(유사도)**를 계산할 수 있음 (왕-남자=여왕) |\n",
                "| **단점** | 단어가 많아지면 메모리 터짐 | 학습이 필요하고, 숫자를 눈으로 보면 뭔지 모름 |\n",
                "| **대표 선수** | BoW, IPvOne-Hot, TF-IDF | **Word2Vec**, FastText, BERT |"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 🌳 그림으로 보기\n",
                "![](https://d.pr/i/zLBglx+)\n",
                "\n",
                "*   왼쪽(Local)은 그냥 각자 따로 노는 거고,\n",
                "*   오른쪽(Continuous)은 의미 공간 안에서 서로 관계를 맺고 있는 거야."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 🎓 정리\n",
                "\n",
                "우리는 이제부터 이 순서대로 배울 거야.\n",
                "\n",
                "1.  **Count 기반 (BoW, TF-IDF)**: \"야, 이 단어 몇 번 나왔어?\" (단순 무식)\n",
                "2.  **Embedding (Word2Vec)**: \"이 단어랑 비슷한 뉘앙스의 단어가 뭐야?\" (AI 다운 접근)\n",
                "\n",
                "자, 그럼 가장 기초적인 **숫자 세기(BoW)**부터 하러 가보자! 👉 **02_bow_tfidf.ipynb**"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "nlp_env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
